<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jeff Helzner">
<meta name="dcterms.date" content="2026-02-10">

<title>m_0_theory â€“ SEU Sensitivity</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-4d9afe2b8d18ee9fa5d0d57b5ed4214d.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1fe82abf2a7e37c817ee6adf46d66500.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-6cc1a338d8c1e7ab9fce866626f20738.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-1fe82abf2a7e37c817ee6adf46d66500.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../../styles/seu-sensitivity.css">
<meta name="citation_author" content="Jeff Helzner">
<meta name="citation_publication_date" content="2026-02-10">
<meta name="citation_cover_date" content="2026-02-10">
<meta name="citation_year" content="2026">
<meta name="citation_online_date" content="2026-02-10">
<meta name="citation_fulltext_html_url" content="https://jeffhelzner.github.io/seu-sensitivity/legacy/theory/m_0_theory.html">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="SEU Sensitivity Project">
<meta name="citation_reference" content="citation_title=Theory of games and economic behavior;,citation_author=John Neumann;,citation_author=Oskar Morgenstern;,citation_publication_date=1947;,citation_cover_date=1947;,citation_year=1947;">
<meta name="citation_reference" content="citation_title=The foundations of statistics;,citation_author=Leonard J. Savage;,citation_publication_date=1954;,citation_cover_date=1954;,citation_year=1954;,citation_publisher=John Wiley &amp;amp;amp; Sons;">
<meta name="citation_reference" content="citation_title=Individual choice behavior: A theoretical analysis;,citation_author=R. Duncan Luce;,citation_publication_date=1959;,citation_cover_date=1959;,citation_year=1959;,citation_publisher=John Wiley &amp;amp;amp; Sons;">
<meta name="citation_reference" content="citation_title=Conditional logit analysis of qualitative choice behavior;,citation_author=Daniel McFadden;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_journal_title=Frontiers in Econometrics;,citation_publisher=Academic Press;">
<meta name="citation_reference" content="citation_title=Discrete choice methods with simulation;,citation_author=Kenneth E. Train;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Validating Bayesian inference algorithms with simulation-based calibration;,citation_author=Sean Talts;,citation_author=Michael Betancourt;,citation_author=Daniel Simpson;,citation_author=Aki Vehtari;,citation_author=Andrew Gelman;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=arXiv preprint arXiv:1804.06788;">
<meta name="citation_reference" content="citation_title=Bayesian workflow;,citation_author=Andrew Gelman;,citation_author=Aki Vehtari;,citation_author=Daniel Simpson;,citation_author=Charles C. Margossian;,citation_author=Bob Carpenter;,citation_author=Yuling Yao;,citation_author=Lauren Kennedy;,citation_author=Jonah Gabry;,citation_author=Paul-Christian BÃ¼rkner;,citation_author=Martin ModrÃ¡k;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_journal_title=arXiv preprint arXiv:2011.01808;">
<meta name="citation_reference" content="citation_title=Stan: A probabilistic programming language;,citation_author=Bob Carpenter;,citation_author=Andrew Gelman;,citation_author=Matthew D. Hoffman;,citation_author=Daniel Lee;,citation_author=Ben Goodrich;,citation_author=Michael Betancourt;,citation_author=Marcus Brubaker;,citation_author=Jiqiang Guo;,citation_author=Peter Li;,citation_author=Allen Riddell;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=76;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=Visualization in Bayesian workflow;,citation_author=Jonah Gabry;,citation_author=Daniel Simpson;,citation_author=Aki Vehtari;,citation_author=Michael Betancourt;,citation_author=Andrew Gelman;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=2;,citation_volume=182;,citation_journal_title=Journal of the Royal Statistical Society: Series A;">
<meta name="citation_reference" content="citation_title=The logic of decision;,citation_author=Richard C. Jeffrey;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;">
<meta name="citation_reference" content="citation_title=Prospect theory: An analysis of decision under risk;,citation_author=Daniel Kahneman;,citation_author=Amos Tversky;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=2;,citation_volume=47;,citation_journal_title=Econometrica;">
<meta name="citation_reference" content="citation_title=Advances in prospect theory: Cumulative representation of uncertainty;,citation_author=Amos Tversky;,citation_author=Daniel Kahneman;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=4;,citation_volume=5;,citation_journal_title=Journal of Risk and Uncertainty;">
<meta name="citation_reference" content="citation_title=The enterprise of knowledge: An essay on knowledge, credal probability, and chance;,citation_author=Isaac Levi;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;">
<meta name="citation_reference" content="citation_title=A behavioral model of rational choice;,citation_author=Herbert A. Simon;,citation_publication_date=1955;,citation_cover_date=1955;,citation_year=1955;,citation_issue=1;,citation_volume=69;,citation_journal_title=The Quarterly Journal of Economics;">
<meta name="citation_reference" content="citation_title=Reasoning the fast and frugal way: Models of bounded rationality;,citation_author=Gerd Gigerenzer;,citation_author=Daniel G. Goldstein;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=103;,citation_inbook_title=Psychological review;">
<meta name="citation_reference" content="citation_title=The methodology of positive economics;,citation_author=Milton Friedman;,citation_publication_date=1953;,citation_cover_date=1953;,citation_year=1953;,citation_journal_title=Essays in Positive Economics;,citation_publisher=University of Chicago Press;">
<meta name="citation_reference" content="citation_title=Risk, uncertainty and profit;,citation_author=Frank H. Knight;,citation_publication_date=1921;,citation_cover_date=1921;,citation_year=1921;">
<meta name="citation_reference" content="citation_title=Theory of games and economic behavior;,citation_author=John Neumann;,citation_author=Oskar Morgenstern;,citation_publication_date=1944;,citation_cover_date=1944;,citation_year=1944;">
<meta name="citation_reference" content="citation_title=The foundations of statistics;,citation_author=Leonard J. Savage;,citation_publication_date=1954;,citation_cover_date=1954;,citation_year=1954;">
<meta name="citation_reference" content="citation_title=A definition of subjective probability;,citation_author=Francis J. Anscombe;,citation_author=Robert J. Aumann;,citation_publication_date=1963;,citation_cover_date=1963;,citation_year=1963;,citation_issue=1;,citation_volume=34;,citation_journal_title=Annals of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Notes on the theory of choice;,citation_author=David M. Kreps;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;">
</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">SEU Sensitivity</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-foundations" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Foundations</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-foundations">    
        <li>
    <a class="dropdown-item" href="../../foundations/01_abstract_formulation.html">
 <span class="dropdown-text">1. Abstract Formulation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../foundations/02_concrete_implementation.html">
 <span class="dropdown-text">2. Concrete Implementation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../foundations/03_prior_analysis.html">
 <span class="dropdown-text">3. Prior Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../foundations/04_parameter_recovery.html">
 <span class="dropdown-text">4. Parameter Recovery</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../foundations/05_adding_risky_choices.html">
 <span class="dropdown-text">5. Adding Risky Choices</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../foundations/06_sbc_validation.html">
 <span class="dropdown-text">6. SBC Validation</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-applications" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Applications</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-applications">    
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Prompt Framing Study</li>
        <li>
    <a class="dropdown-item" href="../../applications/prompt_framing_study/01_background.html">
 <span class="dropdown-text">1. Background</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../applications/prompt_framing_study/02_pilot_study_1.html">
 <span class="dropdown-text">2. Pilot Study 1</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jeffhelzner/seu-sensitivity"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#theoretical-foundation-for-model-m_0-sensitivity-and-value-maximization" id="toc-theoretical-foundation-for-model-m_0-sensitivity-and-value-maximization" class="nav-link active" data-scroll-target="#theoretical-foundation-for-model-m_0-sensitivity-and-value-maximization"><span class="header-section-number">1</span> Theoretical Foundation for Model m_0: Sensitivity and Value Maximization</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">1.1</span> 1. Introduction</a></li>
  <li><a href="#general-softmax-choice-model" id="toc-general-softmax-choice-model" class="nav-link" data-scroll-target="#general-softmax-choice-model"><span class="header-section-number">1.2</span> 2. General Softmax Choice Model</a>
  <ul class="collapse">
  <li><a href="#notation-and-definitions" id="toc-notation-and-definitions" class="nav-link" data-scroll-target="#notation-and-definitions"><span class="header-section-number">1.2.1</span> 2.1 Notation and Definitions</a></li>
  <li><a href="#softmax-choice-rule" id="toc-softmax-choice-rule" class="nav-link" data-scroll-target="#softmax-choice-rule"><span class="header-section-number">1.2.2</span> 2.2 Softmax Choice Rule</a></li>
  <li><a href="#optimal-alternatives" id="toc-optimal-alternatives" class="nav-link" data-scroll-target="#optimal-alternatives"><span class="header-section-number">1.2.3</span> 2.3 Optimal Alternatives</a></li>
  </ul></li>
  <li><a href="#fundamental-properties-of-softmax-choice" id="toc-fundamental-properties-of-softmax-choice" class="nav-link" data-scroll-target="#fundamental-properties-of-softmax-choice"><span class="header-section-number">1.3</span> 3. Fundamental Properties of Softmax Choice</a>
  <ul class="collapse">
  <li><a href="#property-1-monotonicity-in-sensitivity" id="toc-property-1-monotonicity-in-sensitivity" class="nav-link" data-scroll-target="#property-1-monotonicity-in-sensitivity"><span class="header-section-number">1.3.1</span> Property 1: Monotonicity in Sensitivity</a></li>
  <li><a href="#property-2-perfect-optimization-in-the-limit-Î±" id="toc-property-2-perfect-optimization-in-the-limit-Î±" class="nav-link" data-scroll-target="#property-2-perfect-optimization-in-the-limit-Î±"><span class="header-section-number">1.3.2</span> Property 2: Perfect Optimization in the Limit (Î± â†’ âˆ)</a></li>
  <li><a href="#property-3-uniform-choice-in-the-limit-Î±-0" id="toc-property-3-uniform-choice-in-the-limit-Î±-0" class="nav-link" data-scroll-target="#property-3-uniform-choice-in-the-limit-Î±-0"><span class="header-section-number">1.3.3</span> Property 3: Uniform Choice in the Limit (Î± â†’ 0)</a></li>
  </ul></li>
  <li><a href="#application-to-subjective-expected-utility" id="toc-application-to-subjective-expected-utility" class="nav-link" data-scroll-target="#application-to-subjective-expected-utility"><span class="header-section-number">1.4</span> 4. Application to Subjective Expected Utility</a>
  <ul class="collapse">
  <li><a href="#seu-as-a-value-function" id="toc-seu-as-a-value-function" class="nav-link" data-scroll-target="#seu-as-a-value-function"><span class="header-section-number">1.4.1</span> 4.1 SEU as a Value Function</a></li>
  <li><a href="#seu-maximization-properties" id="toc-seu-maximization-properties" class="nav-link" data-scroll-target="#seu-maximization-properties"><span class="header-section-number">1.4.2</span> 4.2 SEU Maximization Properties</a></li>
  <li><a href="#what-seu-adds" id="toc-what-seu-adds" class="nav-link" data-scroll-target="#what-seu-adds"><span class="header-section-number">1.4.3</span> 4.3 What SEU Adds</a></li>
  <li><a href="#scale-invariance-and-identification-of-sensitivity" id="toc-scale-invariance-and-identification-of-sensitivity" class="nav-link" data-scroll-target="#scale-invariance-and-identification-of-sensitivity"><span class="header-section-number">1.4.4</span> 4.4 Scale Invariance and Identification of Sensitivity</a></li>
  <li><a href="#resolving-the-identification-problem" id="toc-resolving-the-identification-problem" class="nav-link" data-scroll-target="#resolving-the-identification-problem"><span class="header-section-number">1.4.5</span> 4.5 Resolving the Identification Problem</a></li>
  <li><a href="#interpretation-of-Î±-under-normalization" id="toc-interpretation-of-Î±-under-normalization" class="nav-link" data-scroll-target="#interpretation-of-Î±-under-normalization"><span class="header-section-number">1.4.6</span> 4.6 Interpretation of Î± Under Normalization</a></li>
  <li><a href="#why-this-matters-for-model-m_0" id="toc-why-this-matters-for-model-m_0" class="nav-link" data-scroll-target="#why-this-matters-for-model-m_0"><span class="header-section-number">1.4.7</span> 4.7 Why This Matters for Model m_0</a></li>
  </ul></li>
  <li><a href="#model-m_0-specification" id="toc-model-m_0-specification" class="nav-link" data-scroll-target="#model-m_0-specification"><span class="header-section-number">1.5</span> 5. Model m_0 Specification</a>
  <ul class="collapse">
  <li><a href="#constructing-seu-from-features" id="toc-constructing-seu-from-features" class="nav-link" data-scroll-target="#constructing-seu-from-features"><span class="header-section-number">1.5.1</span> 5.1 Constructing SEU from Features</a></li>
  <li><a href="#theoretical-guarantees" id="toc-theoretical-guarantees" class="nav-link" data-scroll-target="#theoretical-guarantees"><span class="header-section-number">1.5.2</span> 5.2 Theoretical Guarantees</a></li>
  <li><a href="#seu-maximizer-selection" id="toc-seu-maximizer-selection" class="nav-link" data-scroll-target="#seu-maximizer-selection"><span class="header-section-number">1.5.3</span> 5.3 SEU Maximizer Selection</a></li>
  </ul></li>
  <li><a href="#implications-for-rational-choice-theory" id="toc-implications-for-rational-choice-theory" class="nav-link" data-scroll-target="#implications-for-rational-choice-theory"><span class="header-section-number">1.6</span> 6. Implications for Rational Choice Theory</a>
  <ul class="collapse">
  <li><a href="#generality-of-results" id="toc-generality-of-results" class="nav-link" data-scroll-target="#generality-of-results"><span class="header-section-number">1.6.1</span> 6.1 Generality of Results</a></li>
  <li><a href="#seu-as-a-rational-standard" id="toc-seu-as-a-rational-standard" class="nav-link" data-scroll-target="#seu-as-a-rational-standard"><span class="header-section-number">1.6.2</span> 6.2 SEU as a Rational Standard</a></li>
  <li><a href="#alternative-value-functions" id="toc-alternative-value-functions" class="nav-link" data-scroll-target="#alternative-value-functions"><span class="header-section-number">1.6.3</span> 6.3 Alternative Value Functions</a></li>
  </ul></li>
  <li><a href="#technical-notes" id="toc-technical-notes" class="nav-link" data-scroll-target="#technical-notes"><span class="header-section-number">1.7</span> 7. Technical Notes</a>
  <ul class="collapse">
  <li><a href="#uniqueness-of-maximum" id="toc-uniqueness-of-maximum" class="nav-link" data-scroll-target="#uniqueness-of-maximum"><span class="header-section-number">1.7.1</span> 7.1 Uniqueness of Maximum</a></li>
  <li><a href="#rate-of-convergence" id="toc-rate-of-convergence" class="nav-link" data-scroll-target="#rate-of-convergence"><span class="header-section-number">1.7.2</span> 7.2 Rate of Convergence</a></li>
  <li><a href="#numerical-implementation" id="toc-numerical-implementation" class="nav-link" data-scroll-target="#numerical-implementation"><span class="header-section-number">1.7.3</span> 7.3 Numerical Implementation</a></li>
  <li><a href="#connection-to-information-theory" id="toc-connection-to-information-theory" class="nav-link" data-scroll-target="#connection-to-information-theory"><span class="header-section-number">1.7.4</span> 7.4 Connection to Information Theory</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">1.8</span> 8. References</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><div class="quarto-title-block"><div class="quarto-title-tools-only"><h1></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p><a href="https://github.com/jeffhelzner">Jeff Helzner</a> </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 10, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="theoretical-foundation-for-model-m_0-sensitivity-and-value-maximization" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Theoretical Foundation for Model m_0: Sensitivity and Value Maximization</h1>
<section id="introduction" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1.1</span> 1. Introduction</h2>
<p>This document establishes the theoretical foundations for our computational model of epistemic agents. We first prove three fundamental properties of the softmax choice model with respect to an arbitrary value function, then show how these properties apply to our specific case where values are subjective expected utilities (SEU). This approach clarifies that the core choice-theoretic results are independent of how values are constructed, while the SEU interpretation provides the substantive behavioral content.</p>
</section>
<section id="general-softmax-choice-model" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="general-softmax-choice-model"><span class="header-section-number">1.2</span> 2. General Softmax Choice Model</h2>
<section id="notation-and-definitions" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="notation-and-definitions"><span class="header-section-number">1.2.1</span> 2.1 Notation and Definitions</h3>
<p>Let: - <strong>A</strong> = {1, 2, â€¦, K} be a finite set of alternatives - <strong>V: A â†’ â„</strong> be an arbitrary value function assigning real-valued utilities to alternatives - <strong>V(j)</strong> âˆˆ â„ denote the value of alternative j - <strong>Î±</strong> âˆˆ â„â‚Š denote the sensitivity parameter</p>
</section>
<section id="softmax-choice-rule" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="softmax-choice-rule"><span class="header-section-number">1.2.2</span> 2.2 Softmax Choice Rule</h3>
<p>The probability that a decision maker selects alternative k âˆˆ <strong>A</strong> is given by:</p>
<pre><code>P(choose k | Î±, V) = exp(Î± Â· V(k)) / Î£â±¼âˆˆA exp(Î± Â· V(j))</code></pre>
<p>This is the Luce choice rule or softmax function.</p>
</section>
<section id="optimal-alternatives" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="optimal-alternatives"><span class="header-section-number">1.2.3</span> 2.3 Optimal Alternatives</h3>
<p>Define the set of value-maximizing alternatives:</p>
<pre><code>A* = {j âˆˆ A : V(j) â‰¥ V(k) for all k âˆˆ A}</code></pre>
<p>Let V* = max{V(j) : j âˆˆ A} denote the maximum value, and Aâ» = A &nbsp;A* denote the set of suboptimal alternatives.</p>
</section>
</section>
<section id="fundamental-properties-of-softmax-choice" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="fundamental-properties-of-softmax-choice"><span class="header-section-number">1.3</span> 3. Fundamental Properties of Softmax Choice</h2>
<p><strong>These properties hold for ANY value function V: A â†’ â„.</strong></p>
<section id="property-1-monotonicity-in-sensitivity" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="property-1-monotonicity-in-sensitivity"><span class="header-section-number">1.3.1</span> Property 1: Monotonicity in Sensitivity</h3>
<p><strong>Statement:</strong> For any value function V: A â†’ â„, holding V fixed: - For k âˆˆ A* (value-maximizing), P(choose k | Î±, V) is strictly increasing in Î± - For j âˆ‰ A* (suboptimal), P(choose j | Î±, V) is strictly decreasing in Î±</p>
<p><strong>Proof:</strong></p>
<p><em>Part A: Value-maximizing alternatives (k âˆˆ A</em>)*</p>
<p>Let k âˆˆ A* such that V(k) = V*. Taking the derivative with respect to Î±:</p>
<pre><code>âˆ‚P(k)/âˆ‚Î± = âˆ‚/âˆ‚Î± [exp(Î±Â·V(k)) / Z(Î±)]</code></pre>
<p>where Z(Î±) = Î£â±¼âˆˆA exp(Î±Â·V(j)) is the partition function.</p>
<p>Using the quotient rule:</p>
<pre><code>âˆ‚P(k)/âˆ‚Î± = [Z(Î±)Â·V(k)Â·exp(Î±Â·V(k)) - exp(Î±Â·V(k))Â·Z'(Î±)] / Z(Î±)Â²
         = P(k)Â·[V(k) - Z'(Î±)/Z(Î±)]</code></pre>
<p>Computing Zâ€™(Î±):</p>
<pre><code>Z'(Î±) = Î£â±¼âˆˆA V(j)Â·exp(Î±Â·V(j))</code></pre>
<p>Therefore:</p>
<pre><code>Z'(Î±)/Z(Î±) = Î£â±¼âˆˆA V(j)Â·P(j) = ğ”¼[V]</code></pre>
<p>where ğ”¼[V] is the expected value under the current choice distribution.</p>
<p>Thus:</p>
<pre><code>âˆ‚P(k)/âˆ‚Î± = P(k)Â·[V(k) - ğ”¼[V]] = P(k)Â·[V* - ğ”¼[V]]</code></pre>
<p>Since V* = max{V(j)} and ğ”¼[V] is a weighted average:</p>
<pre><code>ğ”¼[V] = Î£â±¼âˆˆA P(j)Â·V(j) â‰¤ V*</code></pre>
<p>with equality only when P(k) = 1 for some k âˆˆ A* (which occurs only as Î± â†’ âˆ).</p>
<p>For any finite Î±, we have ğ”¼[V] &lt; V*, so:</p>
<pre><code>âˆ‚P(k)/âˆ‚Î± = P(k)Â·[V* - ğ”¼[V]] &gt; 0</code></pre>
<p><em>Part B: Suboptimal alternatives (j âˆ‰ A</em>)*</p>
<p>For j âˆ‰ A<em>, we have V(j) &lt; V</em>. Following the same derivation:</p>
<pre><code>âˆ‚P(j)/âˆ‚Î± = P(j)Â·[V(j) - ğ”¼[V]]</code></pre>
<p>Since j is suboptimal and A* is non-empty (P(A*) &gt; 0 for all finite Î±):</p>
<pre><code>ğ”¼[V] â‰¥ P(A*)Â·V* + P(j)Â·V(j)
     &gt; P(A*)Â·V(j) + P(j)Â·V(j)    [since V* &gt; V(j)]
     = V(j)</code></pre>
<p>Therefore, V(j) - ğ”¼[V] &lt; 0, and:</p>
<pre><code>âˆ‚P(j)/âˆ‚Î± = P(j)Â·[V(j) - ğ”¼[V]] &lt; 0</code></pre>
<p>â–¡</p>
</section>
<section id="property-2-perfect-optimization-in-the-limit-Î±" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="property-2-perfect-optimization-in-the-limit-Î±"><span class="header-section-number">1.3.2</span> Property 2: Perfect Optimization in the Limit (Î± â†’ âˆ)</h3>
<p><strong>Statement:</strong> For any value function V: A â†’ â„, as Î± â†’ âˆ:</p>
<pre><code>lim_{Î±â†’âˆ} P(choose k | Î±, V) = {
    1/|A*|  if k âˆˆ A*
    0       if k âˆ‰ A*
}</code></pre>
<p><strong>Proof:</strong></p>
<p><em>Case 1: k âˆˆ A</em> (value-maximizing)*</p>
<pre><code>P(k) = exp(Î±Â·V*) / [|A*|Â·exp(Î±Â·V*) + Î£â±¼âˆˆAâ» exp(Î±Â·V(j))]</code></pre>
<p>Dividing by exp(Î±Â·V*):</p>
<pre><code>P(k) = 1 / [|A*| + Î£â±¼âˆˆAâ» exp(Î±Â·[V(j) - V*])]</code></pre>
<p>For j âˆˆ Aâ», we have V(j) &lt; V<em>, so V(j) - V</em> &lt; 0.</p>
<p>As Î± â†’ âˆ:</p>
<pre><code>exp(Î±Â·[V(j) - V*]) â†’ 0  for all j âˆˆ Aâ»</code></pre>
<p>Thus:</p>
<pre><code>lim_{Î±â†’âˆ} P(k) = 1/|A*|</code></pre>
<p><em>Case 2: j âˆ‰ A</em> (suboptimal)*</p>
<pre><code>P(j) = exp(Î±Â·V(j)) / [Î£â‚˜âˆˆA* exp(Î±Â·V*) + Î£â‚™âˆˆAâ» exp(Î±Â·V(n))]</code></pre>
<p>Dividing by exp(Î±Â·V*):</p>
<pre><code>P(j) = exp(Î±Â·[V(j) - V*]) / [|A*| + Î£â‚™âˆˆAâ» exp(Î±Â·[V(n) - V*])]</code></pre>
<p>Since V(j) - V* &lt; 0: - Numerator â†’ 0 - Denominator â‰¥ |A*| &gt; 0</p>
<p>Therefore:</p>
<pre><code>lim_{Î±â†’âˆ} P(j) = 0</code></pre>
<p>â–¡</p>
</section>
<section id="property-3-uniform-choice-in-the-limit-Î±-0" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="property-3-uniform-choice-in-the-limit-Î±-0"><span class="header-section-number">1.3.3</span> Property 3: Uniform Choice in the Limit (Î± â†’ 0)</h3>
<p><strong>Statement:</strong> For any value function V: A â†’ â„, as Î± â†’ 0:</p>
<pre><code>lim_{Î±â†’0} P(choose k | Î±, V) = 1/|A|  for all k âˆˆ A</code></pre>
<p><strong>Proof:</strong></p>
<p>Using Taylor expansion exp(x) = 1 + x + O(xÂ²):</p>
<pre><code>P(k) = [1 + Î±Â·V(k) + O(Î±Â²)] / [Î£â±¼âˆˆA (1 + Î±Â·V(j) + O(Î±Â²))]
     = [1 + Î±Â·V(k) + O(Î±Â²)] / [|A| + Î±Â·Î£â±¼ V(j) + O(Î±Â²)]</code></pre>
<p>As Î± â†’ 0:</p>
<pre><code>lim_{Î±â†’0} P(k) = 1/|A|</code></pre>
<p><strong>Alternative proof via logarithms:</strong></p>
<pre><code>log P(k) = Î±Â·V(k) - log[Î£â±¼âˆˆA exp(Î±Â·V(j))]</code></pre>
<p>Expanding the log-sum-exp:</p>
<pre><code>log[Î£â±¼âˆˆA exp(Î±Â·V(j))] = log[|A| + Î±Â·Î£â±¼ V(j) + O(Î±Â²)]
                        = log|A| + (Î±Â·Î£â±¼ V(j))/|A| + O(Î±Â²)</code></pre>
<p>Therefore:</p>
<pre><code>log P(k) = Î±Â·V(k) - log|A| - (Î±Â·Î£â±¼ V(j))/|A| + O(Î±Â²)
         = -log|A| + Î±Â·[V(k) - (Î£â±¼ V(j))/|A|] + O(Î±Â²)
         â†’ -log|A|  as Î± â†’ 0</code></pre>
<p>Thus:</p>
<pre><code>lim_{Î±â†’0} P(k) = 1/|A|</code></pre>
<p>â–¡</p>
</section>
</section>
<section id="application-to-subjective-expected-utility" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="application-to-subjective-expected-utility"><span class="header-section-number">1.4</span> 4. Application to Subjective Expected Utility</h2>
<section id="seu-as-a-value-function" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="seu-as-a-value-function"><span class="header-section-number">1.4.1</span> 4.1 SEU as a Value Function</h3>
<p>We now specialize to the case where the value function V is constructed as subjective expected utility:</p>
<p>Let: - <strong>Î©</strong> = {Ï‰â‚, Ï‰â‚‚, â€¦, Ï‰â‚™} be a finite outcome space - <strong>Ï…â±¼(Ï‰áµ¢)</strong> âˆˆ â„ denote the utility of outcome Ï‰áµ¢ under alternative j - <strong>Ïˆâ±¼(Ï‰áµ¢)</strong> âˆˆ [0,1] denote the subjective probability of outcome Ï‰áµ¢ given alternative j, where Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢) = 1</p>
<p>Define the subjective expected utility function:</p>
<pre><code>SEU: A â†’ â„
SEU(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…â±¼(Ï‰áµ¢)</code></pre>
<p><strong>Key observation:</strong> SEU is simply a particular choice of value function V = SEU. Therefore, all three properties proved above apply immediately when we set V(j) = SEU(j).</p>
</section>
<section id="seu-maximization-properties" class="level3" data-number="1.4.2">
<h3 data-number="1.4.2" class="anchored" data-anchor-id="seu-maximization-properties"><span class="header-section-number">1.4.2</span> 4.2 SEU Maximization Properties</h3>
<p>By substituting V = SEU into Properties 1-3, we obtain:</p>
<p><strong>Corollary 1 (Monotonicity for SEU):</strong> Holding Ï… and Ïˆ fixed, higher sensitivity Î± increases the probability of choosing alternatives that maximize SEU.</p>
<p><strong>Corollary 2 (Perfect Rationality):</strong> As Î± â†’ âˆ, the decision maker chooses SEU-maximizing alternatives with probability 1.</p>
<p><strong>Corollary 3 (Random Choice):</strong> As Î± â†’ 0, the decision maker chooses uniformly at random, independent of SEU values.</p>
</section>
<section id="what-seu-adds" class="level3" data-number="1.4.3">
<h3 data-number="1.4.3" class="anchored" data-anchor-id="what-seu-adds"><span class="header-section-number">1.4.3</span> 4.3 What SEU Adds</h3>
<p>While the mathematical properties of softmax choice hold for any value function, the SEU construction provides:</p>
<ol type="1">
<li><p><strong>Interpretability:</strong> Values decompose into beliefs (Ïˆ) and utilities (Ï…), allowing separate analysis of epistemic and preference components</p></li>
<li><p><strong>Normative content:</strong> SEU maximization is a rationality criterion - Properties 1-3 characterize adherence to this normative standard</p></li>
<li><p><strong>Empirical predictions:</strong> The model predicts that choices will track SEU, not other potential value functions, providing testable restrictions</p></li>
<li><p><strong>Parameter identification:</strong> With sufficient choice data and variation in alternatives, we can potentially identify Ïˆ and Ï… separately (not just their product)</p></li>
</ol>
</section>
<section id="scale-invariance-and-identification-of-sensitivity" class="level3" data-number="1.4.4">
<h3 data-number="1.4.4" class="anchored" data-anchor-id="scale-invariance-and-identification-of-sensitivity"><span class="header-section-number">1.4.4</span> 4.4 Scale Invariance and Identification of Sensitivity</h3>
<p>A fundamental property of utility functions in decision theory is that they are unique only up to positive affine transformations. This raises a critical question: how can we meaningfully identify and interpret the sensitivity parameter Î±?</p>
<p><strong>Theorem (Scale Invariance):</strong> Let Ï… be a utility function and define a rescaled utility function:</p>
<pre><code>Ï…Ìƒ(Ï‰) = aÂ·Ï…(Ï‰) + b  where a &gt; 0</code></pre>
<p>Then for any alternative j:</p>
<pre><code>SEU_Ï…Ìƒ(j) = aÂ·SEU_Ï…(j) + b</code></pre>
<p><strong>Proof:</strong></p>
<pre><code>SEU_Ï…Ìƒ(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…Ìƒ(Ï‰áµ¢)
          = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·[aÂ·Ï…(Ï‰áµ¢) + b]
          = aÂ·Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…(Ï‰áµ¢) + bÂ·Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)
          = aÂ·SEU_Ï…(j) + b</code></pre>
<p><strong>Invariance of Choice Probabilities:</strong> Under softmax choice, this transformation leaves probabilities unchanged:</p>
<pre><code>P(j | Î±, Ï…Ìƒ) = exp(Î±Â·SEU_Ï…Ìƒ(j)) / Î£â‚– exp(Î±Â·SEU_Ï…Ìƒ(k))
             = exp(Î±Â·[aÂ·SEU_Ï…(j) + b]) / Î£â‚– exp(Î±Â·[aÂ·SEU_Ï…(k) + b])
             = exp(Î±Â·aÂ·SEU_Ï…(j))Â·exp(Î±Â·b) / [Î£â‚– exp(Î±Â·aÂ·SEU_Ï…(k))Â·exp(Î±Â·b)]
             = exp(Î±Â·aÂ·SEU_Ï…(j)) / Î£â‚– exp(Î±Â·aÂ·SEU_Ï…(k))
             = P(j | Î±Â·a, Ï…)</code></pre>
<p><strong>Key Implication:</strong> The pair (Î±, Ï…) and (Î±Â·a, Ï…Ìƒ) generate identical choice probabilities for any a &gt; 0. This means Î± and the scale of utility are not separately identified from choice data alone.</p>
</section>
<section id="resolving-the-identification-problem" class="level3" data-number="1.4.5">
<h3 data-number="1.4.5" class="anchored" data-anchor-id="resolving-the-identification-problem"><span class="header-section-number">1.4.5</span> 4.5 Resolving the Identification Problem</h3>
<p>To make Î± interpretable as â€œsensitivity to subjective expected utility,â€ we must fix the scale of utility. Model m_0 achieves this through normalization:</p>
<p><strong>Normalization Constraint:</strong> We constrain utilities to lie in [0,1]:</p>
<pre><code>Ï…â‚ = 0  and  Ï…â‚– = 1</code></pre>
<p>This is implemented in m_0 via:</p>
<pre><code>Ï… = cumulative_sum([0, Î´])  where Î´ ~ Dirichlet(1,...,1)</code></pre>
<p>ensuring 0 = Ï…â‚ â‰¤ Ï…â‚‚ â‰¤ â€¦ â‰¤ Ï…â‚– = 1.</p>
<p><strong>Identification Result:</strong> Given this normalization, Î± is identified from choice data as the unique parameter governing sensitivity to differences in subjective expected utility measured on the [0,1] scale.</p>
<p><strong>Formal Statement:</strong> Fix the utility scale by setting min(Ï…) = 0 and max(Ï…) = 1. Then:</p>
<ol type="1">
<li>The likelihood function P(y | Î±, Ïˆ, Ï…) uniquely determines Î±</li>
<li>Different values of Î± yield different choice distributions</li>
<li>Î± has a clear interpretation: it measures sensitivity to expected utility differences on the unit scale</li>
</ol>
<p><strong>Proof of Identification:</strong> Under the normalization Ï… âˆˆ [0,1]:</p>
<ul>
<li>The range of possible SEU values is bounded: SEU(j) âˆˆ [0,1] for all j</li>
<li>The maximum difference in SEU between any two alternatives is bounded: |SEU(j) - SEU(k)| â‰¤ 1</li>
<li>Therefore, Î± directly controls the log-odds ratio between alternatives:</li>
</ul>
<pre><code>log[P(j)/P(k)] = Î±Â·[SEU(j) - SEU(k)]</code></pre>
<p>where SEU differences are measured in standardized units.</p>
<p>Since log-odds ratios are directly observable in choice data (via choice frequencies), and SEU differences are determined by (Ïˆ, Ï…), the parameter Î± is identified.</p>
</section>
<section id="interpretation-of-Î±-under-normalization" class="level3" data-number="1.4.6">
<h3 data-number="1.4.6" class="anchored" data-anchor-id="interpretation-of-Î±-under-normalization"><span class="header-section-number">1.4.6</span> 4.6 Interpretation of Î± Under Normalization</h3>
<p>With utilities normalized to [0,1], Î± has a precise interpretation:</p>
<p><strong>Î± = 1:</strong> A one-unit difference in SEU (the maximum possible difference) produces a log-odds ratio of 1, corresponding to:</p>
<pre><code>P(better)/P(worse) = e â‰ˆ 2.72</code></pre>
<p>The better alternative is chosen with probability â‰ˆ 73%.</p>
<p><strong>Î± = 2:</strong> A one-unit SEU difference produces log-odds of 2:</p>
<pre><code>P(better)/P(worse) = eÂ² â‰ˆ 7.39</code></pre>
<p>The better alternative is chosen with probability â‰ˆ 88%.</p>
<p><strong>Î± = 5:</strong> A one-unit SEU difference produces log-odds of 5:</p>
<pre><code>P(better)/P(worse) = eâµ â‰ˆ 148</code></pre>
<p>The better alternative is chosen with probability â‰ˆ 99%.</p>
<p><strong>General interpretation:</strong> Î± measures the log-odds change per unit of standardized SEU difference. Higher Î± means choices become more deterministically aligned with SEU rankings.</p>
</section>
<section id="why-this-matters-for-model-m_0" class="level3" data-number="1.4.7">
<h3 data-number="1.4.7" class="anchored" data-anchor-id="why-this-matters-for-model-m_0"><span class="header-section-number">1.4.7</span> 4.7 Why This Matters for Model m_0</h3>
<p>The normalization and identification results ensure that:</p>
<ol type="1">
<li><p><strong>Posterior inferences about Î± are meaningful:</strong> When we infer Î± â‰ˆ 3 from data, this means the decision makerâ€™s log-odds of choosing between alternatives changes by approximately 3 for each unit difference in normalized SEU.</p></li>
<li><p><strong>Cross-study comparability:</strong> Two studies using the same normalization can meaningfully compare estimated Î± values - they measure sensitivity on the same scale.</p></li>
<li><p><strong>Prior specification is interpretable:</strong> When we set <code>alpha ~ lognormal(0, 1)</code>, weâ€™re placing prior mass on interpretable sensitivity levels relative to the unit scale.</p></li>
<li><p><strong>Model predictions are identifiable:</strong> The model makes sharp predictions about choice probabilities given (Ïˆ, Ï…, Î±), and these parameters can be separately estimated from sufficiently rich choice data.</p></li>
</ol>
<p><strong>Without normalization:</strong> We could only identify the product Î±Â·a where a is the unknown utility scale. We couldnâ€™t separately interpret â€œsensitivityâ€ from â€œutility scale.â€</p>
<p><strong>With normalization:</strong> We fix a = 1/(max Ï… - min Ï…), making Î± interpretable as sensitivity per unit of standardized SEU difference.</p>
</section>
</section>
<section id="model-m_0-specification" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="model-m_0-specification"><span class="header-section-number">1.5</span> 5. Model m_0 Specification</h2>
<section id="constructing-seu-from-features" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="constructing-seu-from-features"><span class="header-section-number">1.5.1</span> 5.1 Constructing SEU from Features</h3>
<p>In model m_0, we parameterize the components of SEU:</p>
<p><strong>Subjective probabilities</strong> are determined by alternative features x through:</p>
<pre><code>Ïˆâ±¼ = softmax(Î² Â· xâ±¼)</code></pre>
<p>where Î² âˆˆ â„^(KÃ—D) maps D-dimensional features to K outcome probabilities.</p>
<p><strong>Utilities</strong> are ordered with incremental differences:</p>
<pre><code>Ï… = cumulative_sum([0, Î´])</code></pre>
<p>where Î´ is a (K-1)-simplex ensuring utilities lie in [0,1] and are strictly ordered.</p>
<p><strong>Subjective expected utility</strong> is then:</p>
<pre><code>SEU(j) = Î£â‚– Ïˆâ±¼â‚– Â· Ï…â‚– = Ïˆâ±¼áµ€Ï…</code></pre>
<p><strong>Choice probabilities</strong> follow:</p>
<pre><code>P(choose j | Î±, Î², Î´, x) = exp(Î± Â· SEU(j)) / Î£â‚– exp(Î± Â· SEU(k))</code></pre>
</section>
<section id="theoretical-guarantees" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="theoretical-guarantees"><span class="header-section-number">1.5.2</span> 5.2 Theoretical Guarantees</h3>
<p>Properties 1-3 ensure that:</p>
<ol type="1">
<li><p>Posterior inference on Î± has a clear interpretation: higher inferred Î± means choices are more consistent with SEU maximization</p></li>
<li><p>The model nests both deterministic SEU maximization (Î± â†’ âˆ) and random choice (Î± â†’ 0) as limiting cases</p></li>
<li><p>Intermediate values of Î± capture bounded rationality where decision makers are sensitive to SEU differences but make probabilistic choices</p></li>
</ol>
</section>
<section id="seu-maximizer-selection" class="level3" data-number="1.5.3">
<h3 data-number="1.5.3" class="anchored" data-anchor-id="seu-maximizer-selection"><span class="header-section-number">1.5.3</span> 5.3 SEU Maximizer Selection</h3>
<p>An important diagnostic for understanding model behavior is tracking whether agents select SEU-maximizing alternatives. For each decision problem m, we can define:</p>
<p><strong>SEU Maximizer Indicator:</strong></p>
<pre><code>I_m = 1 if chosen alternative j* satisfies Î·(j*) = max_j Î·(j)
     0 otherwise</code></pre>
<p>where Î·(j) is the expected utility of alternative j.</p>
<p><strong>Expected SEU Maximizer Selection:</strong> Under the softmax choice model with sensitivity Î±, the probability of selecting an SEU maximizer for problem m is:</p>
<pre><code>P(select SEU max | m, Î±) = Î£_{j âˆˆ A*_m} exp(Î±Â·Î·(j)) / Î£_{k=1}^{N_m} exp(Î±Â·Î·(k))</code></pre>
<p>where A*_m is the set of SEU-maximizing alternatives in problem m.</p>
<p><strong>Theoretical Properties:</strong></p>
<ol type="1">
<li><strong>As Î± â†’ âˆ:</strong> P(select SEU max | m, Î±) â†’ 1 for all m</li>
<li><strong>As Î± â†’ 0:</strong> P(select SEU max | m, Î±) â†’ |A*_m|/N_m (probability under random choice)</li>
<li><strong>Monotonicity:</strong> P(select SEU max | m, Î±) is strictly increasing in Î±</li>
</ol>
<p><strong>Aggregate Analysis:</strong> The total number of SEU maximizers selected across M problems follows:</p>
<pre><code>T = Î£_{m=1}^M I_m</code></pre>
<p>Under prior predictive analysis, T provides a summary measure of how often the model generates â€œrationalâ€ choices given the prior distributions on parameters.</p>
</section>
</section>
<section id="implications-for-rational-choice-theory" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="implications-for-rational-choice-theory"><span class="header-section-number">1.6</span> 6. Implications for Rational Choice Theory</h2>
<section id="generality-of-results" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="generality-of-results"><span class="header-section-number">1.6.1</span> 6.1 Generality of Results</h3>
<p>The fact that Properties 1-3 hold for <em>any</em> value function V reveals an important insight: these properties characterize the softmax choice rule itself, not the specific theory of value.</p>
<p>This means: - The monotonicity, limiting behavior, and convergence properties are <strong>structural features</strong> of softmax choice - They would hold equally for risk-neutral expected value, prospect theory values, or any other value construction - The choice of SEU as our value function is a <strong>substantive theoretical commitment</strong> about what drives behavior</p>
</section>
<section id="seu-as-a-rational-standard" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="seu-as-a-rational-standard"><span class="header-section-number">1.6.2</span> 6.2 SEU as a Rational Standard</h3>
<p>By choosing V = SEU, we commit to SEU maximization as our rationality criterion. This commitment:</p>
<ol type="1">
<li>Aligns with classical Bayesian decision theory (Savage, 1954)</li>
<li>Provides a normative benchmark for evaluating choice behavior</li>
<li>Makes our parameter Î± interpretable as â€œdegree of rationalityâ€ relative to this specific standard</li>
</ol>
</section>
<section id="alternative-value-functions" class="level3" data-number="1.6.3">
<h3 data-number="1.6.3" class="anchored" data-anchor-id="alternative-value-functions"><span class="header-section-number">1.6.3</span> 6.3 Alternative Value Functions</h3>
<p>Our framework could accommodate other value functions: - <strong>Expected value:</strong> V(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï‰áµ¢ (objective outcomes, no utilities) - <strong>Prospect theory:</strong> V(j) = Î£áµ¢ w(Ïˆâ±¼(Ï‰áµ¢))Â·v(Ï…â±¼(Ï‰áµ¢)) (probability weighting, reference dependence) - <strong>Regret theory:</strong> V(j) = f(Ï…â±¼, max_k Ï…â‚–) (comparative evaluation)</p>
<p>Each would satisfy Properties 1-3, but yield different substantive predictions about choice behavior.</p>
</section>
</section>
<section id="technical-notes" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="technical-notes"><span class="header-section-number">1.7</span> 7. Technical Notes</h2>
<section id="uniqueness-of-maximum" class="level3" data-number="1.7.1">
<h3 data-number="1.7.1" class="anchored" data-anchor-id="uniqueness-of-maximum"><span class="header-section-number">1.7.1</span> 7.1 Uniqueness of Maximum</h3>
<p>When |A*| = 1 (unique maximum), Property 2 shows deterministic optimal choice as Î± â†’ âˆ.</p>
<p>When |A<em>| &gt; 1 (multiple optima), the limiting distribution is uniform over A</em>, representing rational indifference between equally valued alternatives.</p>
</section>
<section id="rate-of-convergence" class="level3" data-number="1.7.2">
<h3 data-number="1.7.2" class="anchored" data-anchor-id="rate-of-convergence"><span class="header-section-number">1.7.2</span> 7.2 Rate of Convergence</h3>
<ul>
<li><strong>Property 2 (Î± â†’ âˆ):</strong> Convergence is exponential with rate Î” = min{V* - V(j) : j âˆ‰ A*}</li>
<li><strong>Property 3 (Î± â†’ 0):</strong> Convergence is polynomial (first-order in Î±)</li>
</ul>
</section>
<section id="numerical-implementation" class="level3" data-number="1.7.3">
<h3 data-number="1.7.3" class="anchored" data-anchor-id="numerical-implementation"><span class="header-section-number">1.7.3</span> 7.3 Numerical Implementation</h3>
<p>For computational stability: - Large Î±: Use log-sum-exp trick: log(Î£â±¼ exp(xâ±¼)) = max(x) + log(Î£â±¼ exp(xâ±¼ - max(x))) - Small Î±: Taylor expansion may provide better accuracy than direct evaluation</p>
</section>
<section id="connection-to-information-theory" class="level3" data-number="1.7.4">
<h3 data-number="1.7.4" class="anchored" data-anchor-id="connection-to-information-theory"><span class="header-section-number">1.7.4</span> 7.4 Connection to Information Theory</h3>
<p>The softmax choice model can be derived as the maximum entropy distribution subject to the constraint ğ”¼[V] = c, revealing deep connections to information theory and statistical mechanics.</p>
</section>
</section>
<section id="references" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="references"><span class="header-section-number">1.8</span> 8. References</h2>
<p><strong>Softmax/Luce choice:</strong> - Luce, R. D. (1959). <em>Individual Choice Behavior: A Theoretical Analysis</em> - McFadden, D. (1973). Conditional logit analysis of qualitative choice behavior</p>
<p><strong>Quantal response:</strong> - McKelvey, R. D., &amp; Palfrey, T. R. (1995). Quantal response equilibria for normal form games</p>
<p><strong>Subjective expected utility:</strong> - Savage, L. J. (1954). <em>The Foundations of Statistics</em> - Anscombe, F. J., &amp; Aumann, R. J. (1963). A definition of subjective probability</p>
<p><strong>Information theory connection:</strong> - Jaynes, E. T. (1957). Information theory and statistical mechanics - Cover, T. M., &amp; Thomas, J. A. (2006). <em>Elements of Information Theory</em></p>


<!-- -->

</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{helzner2026,
  author = {Helzner, Jeff},
  date = {2026-02-10},
  url = {https://jeffhelzner.github.io/seu-sensitivity/legacy/theory/m_0_theory.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-helzner2026" class="csl-entry quarto-appendix-citeas" role="listitem">
Helzner, Jeff. 2026. SEU Sensitivity Project. February 10, 2026. <a href="https://jeffhelzner.github.io/seu-sensitivity/legacy/theory/m_0_theory.html">https://jeffhelzner.github.io/seu-sensitivity/legacy/theory/m_0_theory.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/jeffhelzner\.github\.io\/seu-sensitivity\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb46" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Theoretical Foundation for Model m_0: Sensitivity and Value Maximization</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1. Introduction</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>This document establishes the theoretical foundations for our computational model of epistemic agents. We first prove three fundamental properties of the softmax choice model with respect to an arbitrary value function, then show how these properties apply to our specific case where values are subjective expected utilities (SEU). This approach clarifies that the core choice-theoretic results are independent of how values are constructed, while the SEU interpretation provides the substantive behavioral content.</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2. General Softmax Choice Model</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.1 Notation and Definitions</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>Let:</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**A** = {1, 2, ..., K} be a finite set of alternatives</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**V: A â†’ â„** be an arbitrary value function assigning real-valued utilities to alternatives</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**V(j)** âˆˆ â„ denote the value of alternative j</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Î±** âˆˆ â„â‚Š denote the sensitivity parameter</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.2 Softmax Choice Rule</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>The probability that a decision maker selects alternative k âˆˆ **A** is given by:</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a><span class="in">P(choose k | Î±, V) = exp(Î± Â· V(k)) / Î£â±¼âˆˆA exp(Î± Â· V(j))</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>This is the Luce choice rule or softmax function.</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2.3 Optimal Alternatives</span></span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>Define the set of value-maximizing alternatives:</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a><span class="in">A* = {j âˆˆ A : V(j) â‰¥ V(k) for all k âˆˆ A}</span></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>Let V* = max{V(j) : j âˆˆ A} denote the maximum value, and Aâ» = A \ A* denote the set of suboptimal alternatives.</span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3. Fundamental Properties of Softmax Choice</span></span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>**These properties hold for ANY value function V: A â†’ â„.**</span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a><span class="fu">### Property 1: Monotonicity in Sensitivity</span></span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a>**Statement:** For any value function V: A â†’ â„, holding V fixed:</span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For k âˆˆ A* (value-maximizing), P(choose k | Î±, V) is strictly increasing in Î±</span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For j âˆ‰ A* (suboptimal), P(choose j | Î±, V) is strictly decreasing in Î±</span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a>**Proof:**</span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a>*Part A: Value-maximizing alternatives (k âˆˆ A*)*</span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a>Let k âˆˆ A* such that V(k) = V*. Taking the derivative with respect to Î±:</span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a><span class="in">âˆ‚P(k)/âˆ‚Î± = âˆ‚/âˆ‚Î± [exp(Î±Â·V(k)) / Z(Î±)]</span></span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a>where Z(Î±) = Î£â±¼âˆˆA exp(Î±Â·V(j)) is the partition function.</span>
<span id="cb46-58"><a href="#cb46-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a>Using the quotient rule:</span>
<span id="cb46-60"><a href="#cb46-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-61"><a href="#cb46-61" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-62"><a href="#cb46-62" aria-hidden="true" tabindex="-1"></a><span class="in">âˆ‚P(k)/âˆ‚Î± = [Z(Î±)Â·V(k)Â·exp(Î±Â·V(k)) - exp(Î±Â·V(k))Â·Z'(Î±)] / Z(Î±)Â²</span></span>
<span id="cb46-63"><a href="#cb46-63" aria-hidden="true" tabindex="-1"></a><span class="in">         = P(k)Â·[V(k) - Z'(Î±)/Z(Î±)]</span></span>
<span id="cb46-64"><a href="#cb46-64" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-65"><a href="#cb46-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-66"><a href="#cb46-66" aria-hidden="true" tabindex="-1"></a>Computing Z'(Î±):</span>
<span id="cb46-67"><a href="#cb46-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-68"><a href="#cb46-68" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-69"><a href="#cb46-69" aria-hidden="true" tabindex="-1"></a><span class="in">Z'(Î±) = Î£â±¼âˆˆA V(j)Â·exp(Î±Â·V(j))</span></span>
<span id="cb46-70"><a href="#cb46-70" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-71"><a href="#cb46-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-72"><a href="#cb46-72" aria-hidden="true" tabindex="-1"></a>Therefore:</span>
<span id="cb46-73"><a href="#cb46-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-74"><a href="#cb46-74" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-75"><a href="#cb46-75" aria-hidden="true" tabindex="-1"></a><span class="in">Z'(Î±)/Z(Î±) = Î£â±¼âˆˆA V(j)Â·P(j) = ğ”¼[V]</span></span>
<span id="cb46-76"><a href="#cb46-76" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-77"><a href="#cb46-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-78"><a href="#cb46-78" aria-hidden="true" tabindex="-1"></a>where ğ”¼<span class="co">[</span><span class="ot">V</span><span class="co">]</span> is the expected value under the current choice distribution.</span>
<span id="cb46-79"><a href="#cb46-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-80"><a href="#cb46-80" aria-hidden="true" tabindex="-1"></a>Thus:</span>
<span id="cb46-81"><a href="#cb46-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-82"><a href="#cb46-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-83"><a href="#cb46-83" aria-hidden="true" tabindex="-1"></a><span class="in">âˆ‚P(k)/âˆ‚Î± = P(k)Â·[V(k) - ğ”¼[V]] = P(k)Â·[V* - ğ”¼[V]]</span></span>
<span id="cb46-84"><a href="#cb46-84" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-85"><a href="#cb46-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-86"><a href="#cb46-86" aria-hidden="true" tabindex="-1"></a>Since V* = max{V(j)} and ğ”¼<span class="co">[</span><span class="ot">V</span><span class="co">]</span> is a weighted average:</span>
<span id="cb46-87"><a href="#cb46-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-88"><a href="#cb46-88" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-89"><a href="#cb46-89" aria-hidden="true" tabindex="-1"></a><span class="in">ğ”¼[V] = Î£â±¼âˆˆA P(j)Â·V(j) â‰¤ V*</span></span>
<span id="cb46-90"><a href="#cb46-90" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-91"><a href="#cb46-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-92"><a href="#cb46-92" aria-hidden="true" tabindex="-1"></a>with equality only when P(k) = 1 for some k âˆˆ A* (which occurs only as Î± â†’ âˆ).</span>
<span id="cb46-93"><a href="#cb46-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-94"><a href="#cb46-94" aria-hidden="true" tabindex="-1"></a>For any finite Î±, we have ğ”¼<span class="co">[</span><span class="ot">V</span><span class="co">]</span> &lt; V*, so:</span>
<span id="cb46-95"><a href="#cb46-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-96"><a href="#cb46-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-97"><a href="#cb46-97" aria-hidden="true" tabindex="-1"></a><span class="in">âˆ‚P(k)/âˆ‚Î± = P(k)Â·[V* - ğ”¼[V]] &gt; 0</span></span>
<span id="cb46-98"><a href="#cb46-98" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-99"><a href="#cb46-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-100"><a href="#cb46-100" aria-hidden="true" tabindex="-1"></a>*Part B: Suboptimal alternatives (j âˆ‰ A*)*</span>
<span id="cb46-101"><a href="#cb46-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-102"><a href="#cb46-102" aria-hidden="true" tabindex="-1"></a>For j âˆ‰ A*, we have V(j) &lt; V*. Following the same derivation:</span>
<span id="cb46-103"><a href="#cb46-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-104"><a href="#cb46-104" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-105"><a href="#cb46-105" aria-hidden="true" tabindex="-1"></a><span class="in">âˆ‚P(j)/âˆ‚Î± = P(j)Â·[V(j) - ğ”¼[V]]</span></span>
<span id="cb46-106"><a href="#cb46-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-107"><a href="#cb46-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-108"><a href="#cb46-108" aria-hidden="true" tabindex="-1"></a>Since j is suboptimal and A* is non-empty (P(A*) &gt; 0 for all finite Î±):</span>
<span id="cb46-109"><a href="#cb46-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-110"><a href="#cb46-110" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-111"><a href="#cb46-111" aria-hidden="true" tabindex="-1"></a><span class="in">ğ”¼[V] â‰¥ P(A*)Â·V* + P(j)Â·V(j)</span></span>
<span id="cb46-112"><a href="#cb46-112" aria-hidden="true" tabindex="-1"></a><span class="in">     &gt; P(A*)Â·V(j) + P(j)Â·V(j)    [since V* &gt; V(j)]</span></span>
<span id="cb46-113"><a href="#cb46-113" aria-hidden="true" tabindex="-1"></a><span class="in">     = V(j)</span></span>
<span id="cb46-114"><a href="#cb46-114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-115"><a href="#cb46-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-116"><a href="#cb46-116" aria-hidden="true" tabindex="-1"></a>Therefore, V(j) - ğ”¼<span class="co">[</span><span class="ot">V</span><span class="co">]</span> &lt; 0, and:</span>
<span id="cb46-117"><a href="#cb46-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-118"><a href="#cb46-118" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-119"><a href="#cb46-119" aria-hidden="true" tabindex="-1"></a><span class="in">âˆ‚P(j)/âˆ‚Î± = P(j)Â·[V(j) - ğ”¼[V]] &lt; 0</span></span>
<span id="cb46-120"><a href="#cb46-120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-121"><a href="#cb46-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-122"><a href="#cb46-122" aria-hidden="true" tabindex="-1"></a>â–¡</span>
<span id="cb46-123"><a href="#cb46-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-124"><a href="#cb46-124" aria-hidden="true" tabindex="-1"></a><span class="fu">### Property 2: Perfect Optimization in the Limit (Î± â†’ âˆ)</span></span>
<span id="cb46-125"><a href="#cb46-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-126"><a href="#cb46-126" aria-hidden="true" tabindex="-1"></a>**Statement:** For any value function V: A â†’ â„, as Î± â†’ âˆ:</span>
<span id="cb46-127"><a href="#cb46-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-128"><a href="#cb46-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-129"><a href="#cb46-129" aria-hidden="true" tabindex="-1"></a><span class="in">lim_{Î±â†’âˆ} P(choose k | Î±, V) = {</span></span>
<span id="cb46-130"><a href="#cb46-130" aria-hidden="true" tabindex="-1"></a><span class="in">    1/|A*|  if k âˆˆ A*</span></span>
<span id="cb46-131"><a href="#cb46-131" aria-hidden="true" tabindex="-1"></a><span class="in">    0       if k âˆ‰ A*</span></span>
<span id="cb46-132"><a href="#cb46-132" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb46-133"><a href="#cb46-133" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-134"><a href="#cb46-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-135"><a href="#cb46-135" aria-hidden="true" tabindex="-1"></a>**Proof:**</span>
<span id="cb46-136"><a href="#cb46-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-137"><a href="#cb46-137" aria-hidden="true" tabindex="-1"></a>*Case 1: k âˆˆ A* (value-maximizing)*</span>
<span id="cb46-138"><a href="#cb46-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-139"><a href="#cb46-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-140"><a href="#cb46-140" aria-hidden="true" tabindex="-1"></a><span class="in">P(k) = exp(Î±Â·V*) / [|A*|Â·exp(Î±Â·V*) + Î£â±¼âˆˆAâ» exp(Î±Â·V(j))]</span></span>
<span id="cb46-141"><a href="#cb46-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-142"><a href="#cb46-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-143"><a href="#cb46-143" aria-hidden="true" tabindex="-1"></a>Dividing by exp(Î±Â·V*):</span>
<span id="cb46-144"><a href="#cb46-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-145"><a href="#cb46-145" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-146"><a href="#cb46-146" aria-hidden="true" tabindex="-1"></a><span class="in">P(k) = 1 / [|A*| + Î£â±¼âˆˆAâ» exp(Î±Â·[V(j) - V*])]</span></span>
<span id="cb46-147"><a href="#cb46-147" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-148"><a href="#cb46-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-149"><a href="#cb46-149" aria-hidden="true" tabindex="-1"></a>For j âˆˆ Aâ», we have V(j) &lt; V*, so V(j) - V* &lt; 0.</span>
<span id="cb46-150"><a href="#cb46-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-151"><a href="#cb46-151" aria-hidden="true" tabindex="-1"></a>As Î± â†’ âˆ:</span>
<span id="cb46-152"><a href="#cb46-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-153"><a href="#cb46-153" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-154"><a href="#cb46-154" aria-hidden="true" tabindex="-1"></a><span class="in">exp(Î±Â·[V(j) - V*]) â†’ 0  for all j âˆˆ Aâ»</span></span>
<span id="cb46-155"><a href="#cb46-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-156"><a href="#cb46-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-157"><a href="#cb46-157" aria-hidden="true" tabindex="-1"></a>Thus:</span>
<span id="cb46-158"><a href="#cb46-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-159"><a href="#cb46-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-160"><a href="#cb46-160" aria-hidden="true" tabindex="-1"></a><span class="in">lim_{Î±â†’âˆ} P(k) = 1/|A*|</span></span>
<span id="cb46-161"><a href="#cb46-161" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-162"><a href="#cb46-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-163"><a href="#cb46-163" aria-hidden="true" tabindex="-1"></a>*Case 2: j âˆ‰ A* (suboptimal)*</span>
<span id="cb46-164"><a href="#cb46-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-165"><a href="#cb46-165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-166"><a href="#cb46-166" aria-hidden="true" tabindex="-1"></a><span class="in">P(j) = exp(Î±Â·V(j)) / [Î£â‚˜âˆˆA* exp(Î±Â·V*) + Î£â‚™âˆˆAâ» exp(Î±Â·V(n))]</span></span>
<span id="cb46-167"><a href="#cb46-167" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-168"><a href="#cb46-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-169"><a href="#cb46-169" aria-hidden="true" tabindex="-1"></a>Dividing by exp(Î±Â·V*):</span>
<span id="cb46-170"><a href="#cb46-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-171"><a href="#cb46-171" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-172"><a href="#cb46-172" aria-hidden="true" tabindex="-1"></a><span class="in">P(j) = exp(Î±Â·[V(j) - V*]) / [|A*| + Î£â‚™âˆˆAâ» exp(Î±Â·[V(n) - V*])]</span></span>
<span id="cb46-173"><a href="#cb46-173" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-174"><a href="#cb46-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-175"><a href="#cb46-175" aria-hidden="true" tabindex="-1"></a>Since V(j) - V* &lt; 0:</span>
<span id="cb46-176"><a href="#cb46-176" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Numerator â†’ 0</span>
<span id="cb46-177"><a href="#cb46-177" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Denominator â‰¥ |A*| &gt; 0</span>
<span id="cb46-178"><a href="#cb46-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-179"><a href="#cb46-179" aria-hidden="true" tabindex="-1"></a>Therefore:</span>
<span id="cb46-180"><a href="#cb46-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-181"><a href="#cb46-181" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-182"><a href="#cb46-182" aria-hidden="true" tabindex="-1"></a><span class="in">lim_{Î±â†’âˆ} P(j) = 0</span></span>
<span id="cb46-183"><a href="#cb46-183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-184"><a href="#cb46-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-185"><a href="#cb46-185" aria-hidden="true" tabindex="-1"></a>â–¡</span>
<span id="cb46-186"><a href="#cb46-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-187"><a href="#cb46-187" aria-hidden="true" tabindex="-1"></a><span class="fu">### Property 3: Uniform Choice in the Limit (Î± â†’ 0)</span></span>
<span id="cb46-188"><a href="#cb46-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-189"><a href="#cb46-189" aria-hidden="true" tabindex="-1"></a>**Statement:** For any value function V: A â†’ â„, as Î± â†’ 0:</span>
<span id="cb46-190"><a href="#cb46-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-191"><a href="#cb46-191" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-192"><a href="#cb46-192" aria-hidden="true" tabindex="-1"></a><span class="in">lim_{Î±â†’0} P(choose k | Î±, V) = 1/|A|  for all k âˆˆ A</span></span>
<span id="cb46-193"><a href="#cb46-193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-194"><a href="#cb46-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-195"><a href="#cb46-195" aria-hidden="true" tabindex="-1"></a>**Proof:**</span>
<span id="cb46-196"><a href="#cb46-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-197"><a href="#cb46-197" aria-hidden="true" tabindex="-1"></a>Using Taylor expansion exp(x) = 1 + x + O(xÂ²):</span>
<span id="cb46-198"><a href="#cb46-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-199"><a href="#cb46-199" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-200"><a href="#cb46-200" aria-hidden="true" tabindex="-1"></a><span class="in">P(k) = [1 + Î±Â·V(k) + O(Î±Â²)] / [Î£â±¼âˆˆA (1 + Î±Â·V(j) + O(Î±Â²))]</span></span>
<span id="cb46-201"><a href="#cb46-201" aria-hidden="true" tabindex="-1"></a><span class="in">     = [1 + Î±Â·V(k) + O(Î±Â²)] / [|A| + Î±Â·Î£â±¼ V(j) + O(Î±Â²)]</span></span>
<span id="cb46-202"><a href="#cb46-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-203"><a href="#cb46-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-204"><a href="#cb46-204" aria-hidden="true" tabindex="-1"></a>As Î± â†’ 0:</span>
<span id="cb46-205"><a href="#cb46-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-206"><a href="#cb46-206" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-207"><a href="#cb46-207" aria-hidden="true" tabindex="-1"></a><span class="in">lim_{Î±â†’0} P(k) = 1/|A|</span></span>
<span id="cb46-208"><a href="#cb46-208" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-209"><a href="#cb46-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-210"><a href="#cb46-210" aria-hidden="true" tabindex="-1"></a>**Alternative proof via logarithms:**</span>
<span id="cb46-211"><a href="#cb46-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-212"><a href="#cb46-212" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-213"><a href="#cb46-213" aria-hidden="true" tabindex="-1"></a><span class="in">log P(k) = Î±Â·V(k) - log[Î£â±¼âˆˆA exp(Î±Â·V(j))]</span></span>
<span id="cb46-214"><a href="#cb46-214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-215"><a href="#cb46-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-216"><a href="#cb46-216" aria-hidden="true" tabindex="-1"></a>Expanding the log-sum-exp:</span>
<span id="cb46-217"><a href="#cb46-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-218"><a href="#cb46-218" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-219"><a href="#cb46-219" aria-hidden="true" tabindex="-1"></a><span class="in">log[Î£â±¼âˆˆA exp(Î±Â·V(j))] = log[|A| + Î±Â·Î£â±¼ V(j) + O(Î±Â²)]</span></span>
<span id="cb46-220"><a href="#cb46-220" aria-hidden="true" tabindex="-1"></a><span class="in">                        = log|A| + (Î±Â·Î£â±¼ V(j))/|A| + O(Î±Â²)</span></span>
<span id="cb46-221"><a href="#cb46-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-222"><a href="#cb46-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-223"><a href="#cb46-223" aria-hidden="true" tabindex="-1"></a>Therefore:</span>
<span id="cb46-224"><a href="#cb46-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-225"><a href="#cb46-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-226"><a href="#cb46-226" aria-hidden="true" tabindex="-1"></a><span class="in">log P(k) = Î±Â·V(k) - log|A| - (Î±Â·Î£â±¼ V(j))/|A| + O(Î±Â²)</span></span>
<span id="cb46-227"><a href="#cb46-227" aria-hidden="true" tabindex="-1"></a><span class="in">         = -log|A| + Î±Â·[V(k) - (Î£â±¼ V(j))/|A|] + O(Î±Â²)</span></span>
<span id="cb46-228"><a href="#cb46-228" aria-hidden="true" tabindex="-1"></a><span class="in">         â†’ -log|A|  as Î± â†’ 0</span></span>
<span id="cb46-229"><a href="#cb46-229" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-230"><a href="#cb46-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-231"><a href="#cb46-231" aria-hidden="true" tabindex="-1"></a>Thus:</span>
<span id="cb46-232"><a href="#cb46-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-233"><a href="#cb46-233" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-234"><a href="#cb46-234" aria-hidden="true" tabindex="-1"></a><span class="in">lim_{Î±â†’0} P(k) = 1/|A|</span></span>
<span id="cb46-235"><a href="#cb46-235" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-236"><a href="#cb46-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-237"><a href="#cb46-237" aria-hidden="true" tabindex="-1"></a>â–¡</span>
<span id="cb46-238"><a href="#cb46-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-239"><a href="#cb46-239" aria-hidden="true" tabindex="-1"></a><span class="fu">## 4. Application to Subjective Expected Utility</span></span>
<span id="cb46-240"><a href="#cb46-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-241"><a href="#cb46-241" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.1 SEU as a Value Function</span></span>
<span id="cb46-242"><a href="#cb46-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-243"><a href="#cb46-243" aria-hidden="true" tabindex="-1"></a>We now specialize to the case where the value function V is constructed as subjective expected utility:</span>
<span id="cb46-244"><a href="#cb46-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-245"><a href="#cb46-245" aria-hidden="true" tabindex="-1"></a>Let:</span>
<span id="cb46-246"><a href="#cb46-246" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Î©** = {Ï‰â‚, Ï‰â‚‚, ..., Ï‰â‚™} be a finite outcome space</span>
<span id="cb46-247"><a href="#cb46-247" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Ï…â±¼(Ï‰áµ¢)** âˆˆ â„ denote the utility of outcome Ï‰áµ¢ under alternative j</span>
<span id="cb46-248"><a href="#cb46-248" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Ïˆâ±¼(Ï‰áµ¢)** âˆˆ <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span> denote the subjective probability of outcome Ï‰áµ¢ given alternative j, where Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢) = 1</span>
<span id="cb46-249"><a href="#cb46-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-250"><a href="#cb46-250" aria-hidden="true" tabindex="-1"></a>Define the subjective expected utility function:</span>
<span id="cb46-251"><a href="#cb46-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-252"><a href="#cb46-252" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-253"><a href="#cb46-253" aria-hidden="true" tabindex="-1"></a><span class="in">SEU: A â†’ â„</span></span>
<span id="cb46-254"><a href="#cb46-254" aria-hidden="true" tabindex="-1"></a><span class="in">SEU(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…â±¼(Ï‰áµ¢)</span></span>
<span id="cb46-255"><a href="#cb46-255" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-256"><a href="#cb46-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-257"><a href="#cb46-257" aria-hidden="true" tabindex="-1"></a>**Key observation:** SEU is simply a particular choice of value function V = SEU. Therefore, all three properties proved above apply immediately when we set V(j) = SEU(j).</span>
<span id="cb46-258"><a href="#cb46-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-259"><a href="#cb46-259" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.2 SEU Maximization Properties</span></span>
<span id="cb46-260"><a href="#cb46-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-261"><a href="#cb46-261" aria-hidden="true" tabindex="-1"></a>By substituting V = SEU into Properties 1-3, we obtain:</span>
<span id="cb46-262"><a href="#cb46-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-263"><a href="#cb46-263" aria-hidden="true" tabindex="-1"></a>**Corollary 1 (Monotonicity for SEU):** Holding Ï… and Ïˆ fixed, higher sensitivity Î± increases the probability of choosing alternatives that maximize SEU.</span>
<span id="cb46-264"><a href="#cb46-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-265"><a href="#cb46-265" aria-hidden="true" tabindex="-1"></a>**Corollary 2 (Perfect Rationality):** As Î± â†’ âˆ, the decision maker chooses SEU-maximizing alternatives with probability 1.</span>
<span id="cb46-266"><a href="#cb46-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-267"><a href="#cb46-267" aria-hidden="true" tabindex="-1"></a>**Corollary 3 (Random Choice):** As Î± â†’ 0, the decision maker chooses uniformly at random, independent of SEU values.</span>
<span id="cb46-268"><a href="#cb46-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-269"><a href="#cb46-269" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.3 What SEU Adds</span></span>
<span id="cb46-270"><a href="#cb46-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-271"><a href="#cb46-271" aria-hidden="true" tabindex="-1"></a>While the mathematical properties of softmax choice hold for any value function, the SEU construction provides:</span>
<span id="cb46-272"><a href="#cb46-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-273"><a href="#cb46-273" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Interpretability:** Values decompose into beliefs (Ïˆ) and utilities (Ï…), allowing separate analysis of epistemic and preference components</span>
<span id="cb46-274"><a href="#cb46-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-275"><a href="#cb46-275" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Normative content:** SEU maximization is a rationality criterion - Properties 1-3 characterize adherence to this normative standard</span>
<span id="cb46-276"><a href="#cb46-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-277"><a href="#cb46-277" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Empirical predictions:** The model predicts that choices will track SEU, not other potential value functions, providing testable restrictions</span>
<span id="cb46-278"><a href="#cb46-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-279"><a href="#cb46-279" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Parameter identification:** With sufficient choice data and variation in alternatives, we can potentially identify Ïˆ and Ï… separately (not just their product)</span>
<span id="cb46-280"><a href="#cb46-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-281"><a href="#cb46-281" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.4 Scale Invariance and Identification of Sensitivity</span></span>
<span id="cb46-282"><a href="#cb46-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-283"><a href="#cb46-283" aria-hidden="true" tabindex="-1"></a>A fundamental property of utility functions in decision theory is that they are unique only up to positive affine transformations. This raises a critical question: how can we meaningfully identify and interpret the sensitivity parameter Î±?</span>
<span id="cb46-284"><a href="#cb46-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-285"><a href="#cb46-285" aria-hidden="true" tabindex="-1"></a>**Theorem (Scale Invariance):** Let Ï… be a utility function and define a rescaled utility function:</span>
<span id="cb46-286"><a href="#cb46-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-287"><a href="#cb46-287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-288"><a href="#cb46-288" aria-hidden="true" tabindex="-1"></a><span class="in">Ï…Ìƒ(Ï‰) = aÂ·Ï…(Ï‰) + b  where a &gt; 0</span></span>
<span id="cb46-289"><a href="#cb46-289" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-290"><a href="#cb46-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-291"><a href="#cb46-291" aria-hidden="true" tabindex="-1"></a>Then for any alternative j:</span>
<span id="cb46-292"><a href="#cb46-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-293"><a href="#cb46-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-294"><a href="#cb46-294" aria-hidden="true" tabindex="-1"></a><span class="in">SEU_Ï…Ìƒ(j) = aÂ·SEU_Ï…(j) + b</span></span>
<span id="cb46-295"><a href="#cb46-295" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-296"><a href="#cb46-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-297"><a href="#cb46-297" aria-hidden="true" tabindex="-1"></a>**Proof:**</span>
<span id="cb46-298"><a href="#cb46-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-299"><a href="#cb46-299" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-300"><a href="#cb46-300" aria-hidden="true" tabindex="-1"></a><span class="in">SEU_Ï…Ìƒ(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…Ìƒ(Ï‰áµ¢)</span></span>
<span id="cb46-301"><a href="#cb46-301" aria-hidden="true" tabindex="-1"></a><span class="in">          = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·[aÂ·Ï…(Ï‰áµ¢) + b]</span></span>
<span id="cb46-302"><a href="#cb46-302" aria-hidden="true" tabindex="-1"></a><span class="in">          = aÂ·Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…(Ï‰áµ¢) + bÂ·Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)</span></span>
<span id="cb46-303"><a href="#cb46-303" aria-hidden="true" tabindex="-1"></a><span class="in">          = aÂ·SEU_Ï…(j) + b</span></span>
<span id="cb46-304"><a href="#cb46-304" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-305"><a href="#cb46-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-306"><a href="#cb46-306" aria-hidden="true" tabindex="-1"></a>**Invariance of Choice Probabilities:** Under softmax choice, this transformation leaves probabilities unchanged:</span>
<span id="cb46-307"><a href="#cb46-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-308"><a href="#cb46-308" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-309"><a href="#cb46-309" aria-hidden="true" tabindex="-1"></a><span class="in">P(j | Î±, Ï…Ìƒ) = exp(Î±Â·SEU_Ï…Ìƒ(j)) / Î£â‚– exp(Î±Â·SEU_Ï…Ìƒ(k))</span></span>
<span id="cb46-310"><a href="#cb46-310" aria-hidden="true" tabindex="-1"></a><span class="in">             = exp(Î±Â·[aÂ·SEU_Ï…(j) + b]) / Î£â‚– exp(Î±Â·[aÂ·SEU_Ï…(k) + b])</span></span>
<span id="cb46-311"><a href="#cb46-311" aria-hidden="true" tabindex="-1"></a><span class="in">             = exp(Î±Â·aÂ·SEU_Ï…(j))Â·exp(Î±Â·b) / [Î£â‚– exp(Î±Â·aÂ·SEU_Ï…(k))Â·exp(Î±Â·b)]</span></span>
<span id="cb46-312"><a href="#cb46-312" aria-hidden="true" tabindex="-1"></a><span class="in">             = exp(Î±Â·aÂ·SEU_Ï…(j)) / Î£â‚– exp(Î±Â·aÂ·SEU_Ï…(k))</span></span>
<span id="cb46-313"><a href="#cb46-313" aria-hidden="true" tabindex="-1"></a><span class="in">             = P(j | Î±Â·a, Ï…)</span></span>
<span id="cb46-314"><a href="#cb46-314" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-315"><a href="#cb46-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-316"><a href="#cb46-316" aria-hidden="true" tabindex="-1"></a>**Key Implication:** The pair (Î±, Ï…) and (Î±Â·a, Ï…Ìƒ) generate identical choice probabilities for any a &gt; 0. This means Î± and the scale of utility are not separately identified from choice data alone.</span>
<span id="cb46-317"><a href="#cb46-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-318"><a href="#cb46-318" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.5 Resolving the Identification Problem</span></span>
<span id="cb46-319"><a href="#cb46-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-320"><a href="#cb46-320" aria-hidden="true" tabindex="-1"></a>To make Î± interpretable as "sensitivity to subjective expected utility," we must fix the scale of utility. Model m_0 achieves this through normalization:</span>
<span id="cb46-321"><a href="#cb46-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-322"><a href="#cb46-322" aria-hidden="true" tabindex="-1"></a>**Normalization Constraint:** We constrain utilities to lie in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>:</span>
<span id="cb46-323"><a href="#cb46-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-324"><a href="#cb46-324" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-325"><a href="#cb46-325" aria-hidden="true" tabindex="-1"></a><span class="in">Ï…â‚ = 0  and  Ï…â‚– = 1</span></span>
<span id="cb46-326"><a href="#cb46-326" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-327"><a href="#cb46-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-328"><a href="#cb46-328" aria-hidden="true" tabindex="-1"></a>This is implemented in m_0 via:</span>
<span id="cb46-329"><a href="#cb46-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-330"><a href="#cb46-330" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-331"><a href="#cb46-331" aria-hidden="true" tabindex="-1"></a><span class="in">Ï… = cumulative_sum([0, Î´])  where Î´ ~ Dirichlet(1,...,1)</span></span>
<span id="cb46-332"><a href="#cb46-332" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-333"><a href="#cb46-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-334"><a href="#cb46-334" aria-hidden="true" tabindex="-1"></a>ensuring 0 = Ï…â‚ â‰¤ Ï…â‚‚ â‰¤ ... â‰¤ Ï…â‚– = 1.</span>
<span id="cb46-335"><a href="#cb46-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-336"><a href="#cb46-336" aria-hidden="true" tabindex="-1"></a>**Identification Result:** Given this normalization, Î± is identified from choice data as the unique parameter governing sensitivity to differences in subjective expected utility measured on the <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span> scale.</span>
<span id="cb46-337"><a href="#cb46-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-338"><a href="#cb46-338" aria-hidden="true" tabindex="-1"></a>**Formal Statement:** Fix the utility scale by setting min(Ï…) = 0 and max(Ï…) = 1. Then:</span>
<span id="cb46-339"><a href="#cb46-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-340"><a href="#cb46-340" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>The likelihood function P(y | Î±, Ïˆ, Ï…) uniquely determines Î±</span>
<span id="cb46-341"><a href="#cb46-341" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Different values of Î± yield different choice distributions</span>
<span id="cb46-342"><a href="#cb46-342" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Î± has a clear interpretation: it measures sensitivity to expected utility differences on the unit scale</span>
<span id="cb46-343"><a href="#cb46-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-344"><a href="#cb46-344" aria-hidden="true" tabindex="-1"></a>**Proof of Identification:** Under the normalization Ï… âˆˆ <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>:</span>
<span id="cb46-345"><a href="#cb46-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-346"><a href="#cb46-346" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The range of possible SEU values is bounded: SEU(j) âˆˆ <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span> for all j</span>
<span id="cb46-347"><a href="#cb46-347" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The maximum difference in SEU between any two alternatives is bounded: |SEU(j) - SEU(k)| â‰¤ 1</span>
<span id="cb46-348"><a href="#cb46-348" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Therefore, Î± directly controls the log-odds ratio between alternatives:</span>
<span id="cb46-349"><a href="#cb46-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-350"><a href="#cb46-350" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-351"><a href="#cb46-351" aria-hidden="true" tabindex="-1"></a><span class="in">log[P(j)/P(k)] = Î±Â·[SEU(j) - SEU(k)]</span></span>
<span id="cb46-352"><a href="#cb46-352" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-353"><a href="#cb46-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-354"><a href="#cb46-354" aria-hidden="true" tabindex="-1"></a>where SEU differences are measured in standardized units.</span>
<span id="cb46-355"><a href="#cb46-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-356"><a href="#cb46-356" aria-hidden="true" tabindex="-1"></a>Since log-odds ratios are directly observable in choice data (via choice frequencies), and SEU differences are determined by (Ïˆ, Ï…), the parameter Î± is identified.</span>
<span id="cb46-357"><a href="#cb46-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-358"><a href="#cb46-358" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.6 Interpretation of Î± Under Normalization</span></span>
<span id="cb46-359"><a href="#cb46-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-360"><a href="#cb46-360" aria-hidden="true" tabindex="-1"></a>With utilities normalized to <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>, Î± has a precise interpretation:</span>
<span id="cb46-361"><a href="#cb46-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-362"><a href="#cb46-362" aria-hidden="true" tabindex="-1"></a>**Î± = 1:** A one-unit difference in SEU (the maximum possible difference) produces a log-odds ratio of 1, corresponding to:</span>
<span id="cb46-363"><a href="#cb46-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-364"><a href="#cb46-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-365"><a href="#cb46-365" aria-hidden="true" tabindex="-1"></a><span class="in">P(better)/P(worse) = e â‰ˆ 2.72</span></span>
<span id="cb46-366"><a href="#cb46-366" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-367"><a href="#cb46-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-368"><a href="#cb46-368" aria-hidden="true" tabindex="-1"></a>The better alternative is chosen with probability â‰ˆ 73%.</span>
<span id="cb46-369"><a href="#cb46-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-370"><a href="#cb46-370" aria-hidden="true" tabindex="-1"></a>**Î± = 2:** A one-unit SEU difference produces log-odds of 2:</span>
<span id="cb46-371"><a href="#cb46-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-372"><a href="#cb46-372" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-373"><a href="#cb46-373" aria-hidden="true" tabindex="-1"></a><span class="in">P(better)/P(worse) = eÂ² â‰ˆ 7.39</span></span>
<span id="cb46-374"><a href="#cb46-374" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-375"><a href="#cb46-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-376"><a href="#cb46-376" aria-hidden="true" tabindex="-1"></a>The better alternative is chosen with probability â‰ˆ 88%.</span>
<span id="cb46-377"><a href="#cb46-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-378"><a href="#cb46-378" aria-hidden="true" tabindex="-1"></a>**Î± = 5:** A one-unit SEU difference produces log-odds of 5:</span>
<span id="cb46-379"><a href="#cb46-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-380"><a href="#cb46-380" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-381"><a href="#cb46-381" aria-hidden="true" tabindex="-1"></a><span class="in">P(better)/P(worse) = eâµ â‰ˆ 148</span></span>
<span id="cb46-382"><a href="#cb46-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-383"><a href="#cb46-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-384"><a href="#cb46-384" aria-hidden="true" tabindex="-1"></a>The better alternative is chosen with probability â‰ˆ 99%.</span>
<span id="cb46-385"><a href="#cb46-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-386"><a href="#cb46-386" aria-hidden="true" tabindex="-1"></a>**General interpretation:** Î± measures the log-odds change per unit of standardized SEU difference. Higher Î± means choices become more deterministically aligned with SEU rankings.</span>
<span id="cb46-387"><a href="#cb46-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-388"><a href="#cb46-388" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.7 Why This Matters for Model m_0</span></span>
<span id="cb46-389"><a href="#cb46-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-390"><a href="#cb46-390" aria-hidden="true" tabindex="-1"></a>The normalization and identification results ensure that:</span>
<span id="cb46-391"><a href="#cb46-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-392"><a href="#cb46-392" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Posterior inferences about Î± are meaningful:** When we infer Î± â‰ˆ 3 from data, this means the decision maker's log-odds of choosing between alternatives changes by approximately 3 for each unit difference in normalized SEU.</span>
<span id="cb46-393"><a href="#cb46-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-394"><a href="#cb46-394" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Cross-study comparability:** Two studies using the same normalization can meaningfully compare estimated Î± values - they measure sensitivity on the same scale.</span>
<span id="cb46-395"><a href="#cb46-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-396"><a href="#cb46-396" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Prior specification is interpretable:** When we set <span class="in">`alpha ~ lognormal(0, 1)`</span>, we're placing prior mass on interpretable sensitivity levels relative to the unit scale.</span>
<span id="cb46-397"><a href="#cb46-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-398"><a href="#cb46-398" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Model predictions are identifiable:** The model makes sharp predictions about choice probabilities given (Ïˆ, Ï…, Î±), and these parameters can be separately estimated from sufficiently rich choice data.</span>
<span id="cb46-399"><a href="#cb46-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-400"><a href="#cb46-400" aria-hidden="true" tabindex="-1"></a>**Without normalization:** We could only identify the product Î±Â·a where a is the unknown utility scale. We couldn't separately interpret "sensitivity" from "utility scale."</span>
<span id="cb46-401"><a href="#cb46-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-402"><a href="#cb46-402" aria-hidden="true" tabindex="-1"></a>**With normalization:** We fix a = 1/(max Ï… - min Ï…), making Î± interpretable as sensitivity per unit of standardized SEU difference.</span>
<span id="cb46-403"><a href="#cb46-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-404"><a href="#cb46-404" aria-hidden="true" tabindex="-1"></a><span class="fu">## 5. Model m_0 Specification</span></span>
<span id="cb46-405"><a href="#cb46-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-406"><a href="#cb46-406" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.1 Constructing SEU from Features</span></span>
<span id="cb46-407"><a href="#cb46-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-408"><a href="#cb46-408" aria-hidden="true" tabindex="-1"></a>In model m_0, we parameterize the components of SEU:</span>
<span id="cb46-409"><a href="#cb46-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-410"><a href="#cb46-410" aria-hidden="true" tabindex="-1"></a>**Subjective probabilities** are determined by alternative features x through:</span>
<span id="cb46-411"><a href="#cb46-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-412"><a href="#cb46-412" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-413"><a href="#cb46-413" aria-hidden="true" tabindex="-1"></a><span class="in">Ïˆâ±¼ = softmax(Î² Â· xâ±¼)</span></span>
<span id="cb46-414"><a href="#cb46-414" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-415"><a href="#cb46-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-416"><a href="#cb46-416" aria-hidden="true" tabindex="-1"></a>where Î² âˆˆ â„^(KÃ—D) maps D-dimensional features to K outcome probabilities.</span>
<span id="cb46-417"><a href="#cb46-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-418"><a href="#cb46-418" aria-hidden="true" tabindex="-1"></a>**Utilities** are ordered with incremental differences:</span>
<span id="cb46-419"><a href="#cb46-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-420"><a href="#cb46-420" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-421"><a href="#cb46-421" aria-hidden="true" tabindex="-1"></a><span class="in">Ï… = cumulative_sum([0, Î´])</span></span>
<span id="cb46-422"><a href="#cb46-422" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-423"><a href="#cb46-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-424"><a href="#cb46-424" aria-hidden="true" tabindex="-1"></a>where Î´ is a (K-1)-simplex ensuring utilities lie in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span> and are strictly ordered.</span>
<span id="cb46-425"><a href="#cb46-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-426"><a href="#cb46-426" aria-hidden="true" tabindex="-1"></a>**Subjective expected utility** is then:</span>
<span id="cb46-427"><a href="#cb46-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-428"><a href="#cb46-428" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-429"><a href="#cb46-429" aria-hidden="true" tabindex="-1"></a><span class="in">SEU(j) = Î£â‚– Ïˆâ±¼â‚– Â· Ï…â‚– = Ïˆâ±¼áµ€Ï…</span></span>
<span id="cb46-430"><a href="#cb46-430" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-431"><a href="#cb46-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-432"><a href="#cb46-432" aria-hidden="true" tabindex="-1"></a>**Choice probabilities** follow:</span>
<span id="cb46-433"><a href="#cb46-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-434"><a href="#cb46-434" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-435"><a href="#cb46-435" aria-hidden="true" tabindex="-1"></a><span class="in">P(choose j | Î±, Î², Î´, x) = exp(Î± Â· SEU(j)) / Î£â‚– exp(Î± Â· SEU(k))</span></span>
<span id="cb46-436"><a href="#cb46-436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-437"><a href="#cb46-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-438"><a href="#cb46-438" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.2 Theoretical Guarantees</span></span>
<span id="cb46-439"><a href="#cb46-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-440"><a href="#cb46-440" aria-hidden="true" tabindex="-1"></a>Properties 1-3 ensure that:</span>
<span id="cb46-441"><a href="#cb46-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-442"><a href="#cb46-442" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Posterior inference on Î± has a clear interpretation: higher inferred Î± means choices are more consistent with SEU maximization</span>
<span id="cb46-443"><a href="#cb46-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-444"><a href="#cb46-444" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>The model nests both deterministic SEU maximization (Î± â†’ âˆ) and random choice (Î± â†’ 0) as limiting cases</span>
<span id="cb46-445"><a href="#cb46-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-446"><a href="#cb46-446" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Intermediate values of Î± capture bounded rationality where decision makers are sensitive to SEU differences but make probabilistic choices</span>
<span id="cb46-447"><a href="#cb46-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-448"><a href="#cb46-448" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.3 SEU Maximizer Selection</span></span>
<span id="cb46-449"><a href="#cb46-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-450"><a href="#cb46-450" aria-hidden="true" tabindex="-1"></a>An important diagnostic for understanding model behavior is tracking whether agents select SEU-maximizing alternatives. For each decision problem m, we can define:</span>
<span id="cb46-451"><a href="#cb46-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-452"><a href="#cb46-452" aria-hidden="true" tabindex="-1"></a>**SEU Maximizer Indicator:**</span>
<span id="cb46-453"><a href="#cb46-453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-454"><a href="#cb46-454" aria-hidden="true" tabindex="-1"></a><span class="in">I_m = 1 if chosen alternative j* satisfies Î·(j*) = max_j Î·(j)</span></span>
<span id="cb46-455"><a href="#cb46-455" aria-hidden="true" tabindex="-1"></a><span class="in">     0 otherwise</span></span>
<span id="cb46-456"><a href="#cb46-456" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-457"><a href="#cb46-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-458"><a href="#cb46-458" aria-hidden="true" tabindex="-1"></a>where Î·(j) is the expected utility of alternative j.</span>
<span id="cb46-459"><a href="#cb46-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-460"><a href="#cb46-460" aria-hidden="true" tabindex="-1"></a>**Expected SEU Maximizer Selection:** Under the softmax choice model with sensitivity Î±, the probability of selecting an SEU maximizer for problem m is:</span>
<span id="cb46-461"><a href="#cb46-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-462"><a href="#cb46-462" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-463"><a href="#cb46-463" aria-hidden="true" tabindex="-1"></a><span class="in">P(select SEU max | m, Î±) = Î£_{j âˆˆ A*_m} exp(Î±Â·Î·(j)) / Î£_{k=1}^{N_m} exp(Î±Â·Î·(k))</span></span>
<span id="cb46-464"><a href="#cb46-464" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-465"><a href="#cb46-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-466"><a href="#cb46-466" aria-hidden="true" tabindex="-1"></a>where A*_m is the set of SEU-maximizing alternatives in problem m.</span>
<span id="cb46-467"><a href="#cb46-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-468"><a href="#cb46-468" aria-hidden="true" tabindex="-1"></a>**Theoretical Properties:**</span>
<span id="cb46-469"><a href="#cb46-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-470"><a href="#cb46-470" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**As Î± â†’ âˆ:** P(select SEU max | m, Î±) â†’ 1 for all m</span>
<span id="cb46-471"><a href="#cb46-471" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**As Î± â†’ 0:** P(select SEU max | m, Î±) â†’ |A*_m|/N_m (probability under random choice)</span>
<span id="cb46-472"><a href="#cb46-472" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Monotonicity:** P(select SEU max | m, Î±) is strictly increasing in Î±</span>
<span id="cb46-473"><a href="#cb46-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-474"><a href="#cb46-474" aria-hidden="true" tabindex="-1"></a>**Aggregate Analysis:** The total number of SEU maximizers selected across M problems follows:</span>
<span id="cb46-475"><a href="#cb46-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-476"><a href="#cb46-476" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-477"><a href="#cb46-477" aria-hidden="true" tabindex="-1"></a><span class="in">T = Î£_{m=1}^M I_m</span></span>
<span id="cb46-478"><a href="#cb46-478" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-479"><a href="#cb46-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-480"><a href="#cb46-480" aria-hidden="true" tabindex="-1"></a>Under prior predictive analysis, T provides a summary measure of how often the model generates "rational" choices given the prior distributions on parameters.</span>
<span id="cb46-481"><a href="#cb46-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-482"><a href="#cb46-482" aria-hidden="true" tabindex="-1"></a><span class="fu">## 6. Implications for Rational Choice Theory</span></span>
<span id="cb46-483"><a href="#cb46-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-484"><a href="#cb46-484" aria-hidden="true" tabindex="-1"></a><span class="fu">### 6.1 Generality of Results</span></span>
<span id="cb46-485"><a href="#cb46-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-486"><a href="#cb46-486" aria-hidden="true" tabindex="-1"></a>The fact that Properties 1-3 hold for *any* value function V reveals an important insight: these properties characterize the softmax choice rule itself, not the specific theory of value.</span>
<span id="cb46-487"><a href="#cb46-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-488"><a href="#cb46-488" aria-hidden="true" tabindex="-1"></a>This means:</span>
<span id="cb46-489"><a href="#cb46-489" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The monotonicity, limiting behavior, and convergence properties are **structural features** of softmax choice</span>
<span id="cb46-490"><a href="#cb46-490" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>They would hold equally for risk-neutral expected value, prospect theory values, or any other value construction</span>
<span id="cb46-491"><a href="#cb46-491" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The choice of SEU as our value function is a **substantive theoretical commitment** about what drives behavior</span>
<span id="cb46-492"><a href="#cb46-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-493"><a href="#cb46-493" aria-hidden="true" tabindex="-1"></a><span class="fu">### 6.2 SEU as a Rational Standard</span></span>
<span id="cb46-494"><a href="#cb46-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-495"><a href="#cb46-495" aria-hidden="true" tabindex="-1"></a>By choosing V = SEU, we commit to SEU maximization as our rationality criterion. This commitment:</span>
<span id="cb46-496"><a href="#cb46-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-497"><a href="#cb46-497" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Aligns with classical Bayesian decision theory (Savage, 1954)</span>
<span id="cb46-498"><a href="#cb46-498" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Provides a normative benchmark for evaluating choice behavior</span>
<span id="cb46-499"><a href="#cb46-499" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Makes our parameter Î± interpretable as "degree of rationality" relative to this specific standard</span>
<span id="cb46-500"><a href="#cb46-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-501"><a href="#cb46-501" aria-hidden="true" tabindex="-1"></a><span class="fu">### 6.3 Alternative Value Functions</span></span>
<span id="cb46-502"><a href="#cb46-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-503"><a href="#cb46-503" aria-hidden="true" tabindex="-1"></a>Our framework could accommodate other value functions:</span>
<span id="cb46-504"><a href="#cb46-504" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Expected value:** V(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï‰áµ¢ (objective outcomes, no utilities)</span>
<span id="cb46-505"><a href="#cb46-505" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Prospect theory:** V(j) = Î£áµ¢ w(Ïˆâ±¼(Ï‰áµ¢))Â·v(Ï…â±¼(Ï‰áµ¢)) (probability weighting, reference dependence)</span>
<span id="cb46-506"><a href="#cb46-506" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Regret theory:** V(j) = f(Ï…â±¼, max_k Ï…â‚–) (comparative evaluation)</span>
<span id="cb46-507"><a href="#cb46-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-508"><a href="#cb46-508" aria-hidden="true" tabindex="-1"></a>Each would satisfy Properties 1-3, but yield different substantive predictions about choice behavior.</span>
<span id="cb46-509"><a href="#cb46-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-510"><a href="#cb46-510" aria-hidden="true" tabindex="-1"></a><span class="fu">## 7. Technical Notes</span></span>
<span id="cb46-511"><a href="#cb46-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-512"><a href="#cb46-512" aria-hidden="true" tabindex="-1"></a><span class="fu">### 7.1 Uniqueness of Maximum</span></span>
<span id="cb46-513"><a href="#cb46-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-514"><a href="#cb46-514" aria-hidden="true" tabindex="-1"></a>When |A*| = 1 (unique maximum), Property 2 shows deterministic optimal choice as Î± â†’ âˆ.</span>
<span id="cb46-515"><a href="#cb46-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-516"><a href="#cb46-516" aria-hidden="true" tabindex="-1"></a>When |A*| &gt; 1 (multiple optima), the limiting distribution is uniform over A*, representing rational indifference between equally valued alternatives.</span>
<span id="cb46-517"><a href="#cb46-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-518"><a href="#cb46-518" aria-hidden="true" tabindex="-1"></a><span class="fu">### 7.2 Rate of Convergence</span></span>
<span id="cb46-519"><a href="#cb46-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-520"><a href="#cb46-520" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Property 2 (Î± â†’ âˆ):** Convergence is exponential with rate Î” = min{V* - V(j) : j âˆ‰ A*}</span>
<span id="cb46-521"><a href="#cb46-521" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Property 3 (Î± â†’ 0):** Convergence is polynomial (first-order in Î±)</span>
<span id="cb46-522"><a href="#cb46-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-523"><a href="#cb46-523" aria-hidden="true" tabindex="-1"></a><span class="fu">### 7.3 Numerical Implementation</span></span>
<span id="cb46-524"><a href="#cb46-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-525"><a href="#cb46-525" aria-hidden="true" tabindex="-1"></a>For computational stability:</span>
<span id="cb46-526"><a href="#cb46-526" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Large Î±: Use log-sum-exp trick: log(Î£â±¼ exp(xâ±¼)) = max(x) + log(Î£â±¼ exp(xâ±¼ - max(x)))</span>
<span id="cb46-527"><a href="#cb46-527" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Small Î±: Taylor expansion may provide better accuracy than direct evaluation</span>
<span id="cb46-528"><a href="#cb46-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-529"><a href="#cb46-529" aria-hidden="true" tabindex="-1"></a><span class="fu">### 7.4 Connection to Information Theory</span></span>
<span id="cb46-530"><a href="#cb46-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-531"><a href="#cb46-531" aria-hidden="true" tabindex="-1"></a>The softmax choice model can be derived as the maximum entropy distribution subject to the constraint ğ”¼<span class="co">[</span><span class="ot">V</span><span class="co">]</span> = c, revealing deep connections to information theory and statistical mechanics.</span>
<span id="cb46-532"><a href="#cb46-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-533"><a href="#cb46-533" aria-hidden="true" tabindex="-1"></a><span class="fu">## 8. References</span></span>
<span id="cb46-534"><a href="#cb46-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-535"><a href="#cb46-535" aria-hidden="true" tabindex="-1"></a>**Softmax/Luce choice:**</span>
<span id="cb46-536"><a href="#cb46-536" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Luce, R. D. (1959). *Individual Choice Behavior: A Theoretical Analysis*</span>
<span id="cb46-537"><a href="#cb46-537" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>McFadden, D. (1973). Conditional logit analysis of qualitative choice behavior</span>
<span id="cb46-538"><a href="#cb46-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-539"><a href="#cb46-539" aria-hidden="true" tabindex="-1"></a>**Quantal response:**</span>
<span id="cb46-540"><a href="#cb46-540" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>McKelvey, R. D., &amp; Palfrey, T. R. (1995). Quantal response equilibria for normal form games</span>
<span id="cb46-541"><a href="#cb46-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-542"><a href="#cb46-542" aria-hidden="true" tabindex="-1"></a>**Subjective expected utility:**</span>
<span id="cb46-543"><a href="#cb46-543" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Savage, L. J. (1954). *The Foundations of Statistics*</span>
<span id="cb46-544"><a href="#cb46-544" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Anscombe, F. J., &amp; Aumann, R. J. (1963). A definition of subjective probability</span>
<span id="cb46-545"><a href="#cb46-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-546"><a href="#cb46-546" aria-hidden="true" tabindex="-1"></a>**Information theory connection:**</span>
<span id="cb46-547"><a href="#cb46-547" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Jaynes, E. T. (1957). Information theory and statistical mechanics</span>
<span id="cb46-548"><a href="#cb46-548" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Cover, T. M., &amp; Thomas, J. A. (2006). *Elements of Information Theory*</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>