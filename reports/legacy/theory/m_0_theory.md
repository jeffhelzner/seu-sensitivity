# Theoretical Foundation for Model m_0: Sensitivity and Value Maximization

## 1. Introduction

This document establishes the theoretical foundations for our computational model of epistemic agents. We first prove three fundamental properties of the softmax choice model with respect to an arbitrary value function, then show how these properties apply to our specific case where values are subjective expected utilities (SEU). This approach clarifies that the core choice-theoretic results are independent of how values are constructed, while the SEU interpretation provides the substantive behavioral content.

## 2. General Softmax Choice Model

### 2.1 Notation and Definitions

Let:
- **A** = {1, 2, ..., K} be a finite set of alternatives
- **V: A â†’ â„** be an arbitrary value function assigning real-valued utilities to alternatives
- **V(j)** âˆˆ â„ denote the value of alternative j
- **Î±** âˆˆ â„â‚Š denote the sensitivity parameter

### 2.2 Softmax Choice Rule

The probability that a decision maker selects alternative k âˆˆ **A** is given by:

```
P(choose k | Î±, V) = exp(Î± Â· V(k)) / Î£â±¼âˆˆA exp(Î± Â· V(j))
```

This is the Luce choice rule or softmax function.

### 2.3 Optimal Alternatives

Define the set of value-maximizing alternatives:

```
A* = {j âˆˆ A : V(j) â‰¥ V(k) for all k âˆˆ A}
```

Let V* = max{V(j) : j âˆˆ A} denote the maximum value, and Aâ» = A \ A* denote the set of suboptimal alternatives.

## 3. Fundamental Properties of Softmax Choice

**These properties hold for ANY value function V: A â†’ â„.**

### Property 1: Monotonicity in Sensitivity

**Statement:** For any value function V: A â†’ â„, holding V fixed:
- For k âˆˆ A* (value-maximizing), P(choose k | Î±, V) is strictly increasing in Î±
- For j âˆ‰ A* (suboptimal), P(choose j | Î±, V) is strictly decreasing in Î±

**Proof:**

*Part A: Value-maximizing alternatives (k âˆˆ A*)*

Let k âˆˆ A* such that V(k) = V*. Taking the derivative with respect to Î±:

```
âˆ‚P(k)/âˆ‚Î± = âˆ‚/âˆ‚Î± [exp(Î±Â·V(k)) / Z(Î±)]
```

where Z(Î±) = Î£â±¼âˆˆA exp(Î±Â·V(j)) is the partition function.

Using the quotient rule:

```
âˆ‚P(k)/âˆ‚Î± = [Z(Î±)Â·V(k)Â·exp(Î±Â·V(k)) - exp(Î±Â·V(k))Â·Z'(Î±)] / Z(Î±)Â²
         = P(k)Â·[V(k) - Z'(Î±)/Z(Î±)]
```

Computing Z'(Î±):

```
Z'(Î±) = Î£â±¼âˆˆA V(j)Â·exp(Î±Â·V(j))
```

Therefore:

```
Z'(Î±)/Z(Î±) = Î£â±¼âˆˆA V(j)Â·P(j) = ğ”¼[V]
```

where ğ”¼[V] is the expected value under the current choice distribution.

Thus:

```
âˆ‚P(k)/âˆ‚Î± = P(k)Â·[V(k) - ğ”¼[V]] = P(k)Â·[V* - ğ”¼[V]]
```

Since V* = max{V(j)} and ğ”¼[V] is a weighted average:

```
ğ”¼[V] = Î£â±¼âˆˆA P(j)Â·V(j) â‰¤ V*
```

with equality only when P(k) = 1 for some k âˆˆ A* (which occurs only as Î± â†’ âˆ).

For any finite Î±, we have ğ”¼[V] < V*, so:

```
âˆ‚P(k)/âˆ‚Î± = P(k)Â·[V* - ğ”¼[V]] > 0
```

*Part B: Suboptimal alternatives (j âˆ‰ A*)*

For j âˆ‰ A*, we have V(j) < V*. Following the same derivation:

```
âˆ‚P(j)/âˆ‚Î± = P(j)Â·[V(j) - ğ”¼[V]]
```

Since j is suboptimal and A* is non-empty (P(A*) > 0 for all finite Î±):

```
ğ”¼[V] â‰¥ P(A*)Â·V* + P(j)Â·V(j)
     > P(A*)Â·V(j) + P(j)Â·V(j)    [since V* > V(j)]
     = V(j)
```

Therefore, V(j) - ğ”¼[V] < 0, and:

```
âˆ‚P(j)/âˆ‚Î± = P(j)Â·[V(j) - ğ”¼[V]] < 0
```

â–¡

### Property 2: Perfect Optimization in the Limit (Î± â†’ âˆ)

**Statement:** For any value function V: A â†’ â„, as Î± â†’ âˆ:

```
lim_{Î±â†’âˆ} P(choose k | Î±, V) = {
    1/|A*|  if k âˆˆ A*
    0       if k âˆ‰ A*
}
```

**Proof:**

*Case 1: k âˆˆ A* (value-maximizing)*

```
P(k) = exp(Î±Â·V*) / [|A*|Â·exp(Î±Â·V*) + Î£â±¼âˆˆAâ» exp(Î±Â·V(j))]
```

Dividing by exp(Î±Â·V*):

```
P(k) = 1 / [|A*| + Î£â±¼âˆˆAâ» exp(Î±Â·[V(j) - V*])]
```

For j âˆˆ Aâ», we have V(j) < V*, so V(j) - V* < 0.

As Î± â†’ âˆ:

```
exp(Î±Â·[V(j) - V*]) â†’ 0  for all j âˆˆ Aâ»
```

Thus:

```
lim_{Î±â†’âˆ} P(k) = 1/|A*|
```

*Case 2: j âˆ‰ A* (suboptimal)*

```
P(j) = exp(Î±Â·V(j)) / [Î£â‚˜âˆˆA* exp(Î±Â·V*) + Î£â‚™âˆˆAâ» exp(Î±Â·V(n))]
```

Dividing by exp(Î±Â·V*):

```
P(j) = exp(Î±Â·[V(j) - V*]) / [|A*| + Î£â‚™âˆˆAâ» exp(Î±Â·[V(n) - V*])]
```

Since V(j) - V* < 0:
- Numerator â†’ 0
- Denominator â‰¥ |A*| > 0

Therefore:

```
lim_{Î±â†’âˆ} P(j) = 0
```

â–¡

### Property 3: Uniform Choice in the Limit (Î± â†’ 0)

**Statement:** For any value function V: A â†’ â„, as Î± â†’ 0:

```
lim_{Î±â†’0} P(choose k | Î±, V) = 1/|A|  for all k âˆˆ A
```

**Proof:**

Using Taylor expansion exp(x) = 1 + x + O(xÂ²):

```
P(k) = [1 + Î±Â·V(k) + O(Î±Â²)] / [Î£â±¼âˆˆA (1 + Î±Â·V(j) + O(Î±Â²))]
     = [1 + Î±Â·V(k) + O(Î±Â²)] / [|A| + Î±Â·Î£â±¼ V(j) + O(Î±Â²)]
```

As Î± â†’ 0:

```
lim_{Î±â†’0} P(k) = 1/|A|
```

**Alternative proof via logarithms:**

```
log P(k) = Î±Â·V(k) - log[Î£â±¼âˆˆA exp(Î±Â·V(j))]
```

Expanding the log-sum-exp:

```
log[Î£â±¼âˆˆA exp(Î±Â·V(j))] = log[|A| + Î±Â·Î£â±¼ V(j) + O(Î±Â²)]
                        = log|A| + (Î±Â·Î£â±¼ V(j))/|A| + O(Î±Â²)
```

Therefore:

```
log P(k) = Î±Â·V(k) - log|A| - (Î±Â·Î£â±¼ V(j))/|A| + O(Î±Â²)
         = -log|A| + Î±Â·[V(k) - (Î£â±¼ V(j))/|A|] + O(Î±Â²)
         â†’ -log|A|  as Î± â†’ 0
```

Thus:

```
lim_{Î±â†’0} P(k) = 1/|A|
```

â–¡

## 4. Application to Subjective Expected Utility

### 4.1 SEU as a Value Function

We now specialize to the case where the value function V is constructed as subjective expected utility:

Let:
- **Î©** = {Ï‰â‚, Ï‰â‚‚, ..., Ï‰â‚™} be a finite outcome space
- **Ï…â±¼(Ï‰áµ¢)** âˆˆ â„ denote the utility of outcome Ï‰áµ¢ under alternative j
- **Ïˆâ±¼(Ï‰áµ¢)** âˆˆ [0,1] denote the subjective probability of outcome Ï‰áµ¢ given alternative j, where Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢) = 1

Define the subjective expected utility function:

```
SEU: A â†’ â„
SEU(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…â±¼(Ï‰áµ¢)
```

**Key observation:** SEU is simply a particular choice of value function V = SEU. Therefore, all three properties proved above apply immediately when we set V(j) = SEU(j).

### 4.2 SEU Maximization Properties

By substituting V = SEU into Properties 1-3, we obtain:

**Corollary 1 (Monotonicity for SEU):** Holding Ï… and Ïˆ fixed, higher sensitivity Î± increases the probability of choosing alternatives that maximize SEU.

**Corollary 2 (Perfect Rationality):** As Î± â†’ âˆ, the decision maker chooses SEU-maximizing alternatives with probability 1.

**Corollary 3 (Random Choice):** As Î± â†’ 0, the decision maker chooses uniformly at random, independent of SEU values.

### 4.3 What SEU Adds

While the mathematical properties of softmax choice hold for any value function, the SEU construction provides:

1. **Interpretability:** Values decompose into beliefs (Ïˆ) and utilities (Ï…), allowing separate analysis of epistemic and preference components

2. **Normative content:** SEU maximization is a rationality criterion - Properties 1-3 characterize adherence to this normative standard

3. **Empirical predictions:** The model predicts that choices will track SEU, not other potential value functions, providing testable restrictions

4. **Parameter identification:** With sufficient choice data and variation in alternatives, we can potentially identify Ïˆ and Ï… separately (not just their product)

### 4.4 Scale Invariance and Identification of Sensitivity

A fundamental property of utility functions in decision theory is that they are unique only up to positive affine transformations. This raises a critical question: how can we meaningfully identify and interpret the sensitivity parameter Î±?

**Theorem (Scale Invariance):** Let Ï… be a utility function and define a rescaled utility function:

```
Ï…Ìƒ(Ï‰) = aÂ·Ï…(Ï‰) + b  where a > 0
```

Then for any alternative j:

```
SEU_Ï…Ìƒ(j) = aÂ·SEU_Ï…(j) + b
```

**Proof:**

```
SEU_Ï…Ìƒ(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…Ìƒ(Ï‰áµ¢)
          = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·[aÂ·Ï…(Ï‰áµ¢) + b]
          = aÂ·Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï…(Ï‰áµ¢) + bÂ·Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)
          = aÂ·SEU_Ï…(j) + b
```

**Invariance of Choice Probabilities:** Under softmax choice, this transformation leaves probabilities unchanged:

```
P(j | Î±, Ï…Ìƒ) = exp(Î±Â·SEU_Ï…Ìƒ(j)) / Î£â‚– exp(Î±Â·SEU_Ï…Ìƒ(k))
             = exp(Î±Â·[aÂ·SEU_Ï…(j) + b]) / Î£â‚– exp(Î±Â·[aÂ·SEU_Ï…(k) + b])
             = exp(Î±Â·aÂ·SEU_Ï…(j))Â·exp(Î±Â·b) / [Î£â‚– exp(Î±Â·aÂ·SEU_Ï…(k))Â·exp(Î±Â·b)]
             = exp(Î±Â·aÂ·SEU_Ï…(j)) / Î£â‚– exp(Î±Â·aÂ·SEU_Ï…(k))
             = P(j | Î±Â·a, Ï…)
```

**Key Implication:** The pair (Î±, Ï…) and (Î±Â·a, Ï…Ìƒ) generate identical choice probabilities for any a > 0. This means Î± and the scale of utility are not separately identified from choice data alone.

### 4.5 Resolving the Identification Problem

To make Î± interpretable as "sensitivity to subjective expected utility," we must fix the scale of utility. Model m_0 achieves this through normalization:

**Normalization Constraint:** We constrain utilities to lie in [0,1]:

```
Ï…â‚ = 0  and  Ï…â‚– = 1
```

This is implemented in m_0 via:

```
Ï… = cumulative_sum([0, Î´])  where Î´ ~ Dirichlet(1,...,1)
```

ensuring 0 = Ï…â‚ â‰¤ Ï…â‚‚ â‰¤ ... â‰¤ Ï…â‚– = 1.

**Identification Result:** Given this normalization, Î± is identified from choice data as the unique parameter governing sensitivity to differences in subjective expected utility measured on the [0,1] scale.

**Formal Statement:** Fix the utility scale by setting min(Ï…) = 0 and max(Ï…) = 1. Then:

1. The likelihood function P(y | Î±, Ïˆ, Ï…) uniquely determines Î±
2. Different values of Î± yield different choice distributions
3. Î± has a clear interpretation: it measures sensitivity to expected utility differences on the unit scale

**Proof of Identification:** Under the normalization Ï… âˆˆ [0,1]:

- The range of possible SEU values is bounded: SEU(j) âˆˆ [0,1] for all j
- The maximum difference in SEU between any two alternatives is bounded: |SEU(j) - SEU(k)| â‰¤ 1
- Therefore, Î± directly controls the log-odds ratio between alternatives:

```
log[P(j)/P(k)] = Î±Â·[SEU(j) - SEU(k)]
```

where SEU differences are measured in standardized units.

Since log-odds ratios are directly observable in choice data (via choice frequencies), and SEU differences are determined by (Ïˆ, Ï…), the parameter Î± is identified.

### 4.6 Interpretation of Î± Under Normalization

With utilities normalized to [0,1], Î± has a precise interpretation:

**Î± = 1:** A one-unit difference in SEU (the maximum possible difference) produces a log-odds ratio of 1, corresponding to:

```
P(better)/P(worse) = e â‰ˆ 2.72
```

The better alternative is chosen with probability â‰ˆ 73%.

**Î± = 2:** A one-unit SEU difference produces log-odds of 2:

```
P(better)/P(worse) = eÂ² â‰ˆ 7.39
```

The better alternative is chosen with probability â‰ˆ 88%.

**Î± = 5:** A one-unit SEU difference produces log-odds of 5:

```
P(better)/P(worse) = eâµ â‰ˆ 148
```

The better alternative is chosen with probability â‰ˆ 99%.

**General interpretation:** Î± measures the log-odds change per unit of standardized SEU difference. Higher Î± means choices become more deterministically aligned with SEU rankings.

### 4.7 Why This Matters for Model m_0

The normalization and identification results ensure that:

1. **Posterior inferences about Î± are meaningful:** When we infer Î± â‰ˆ 3 from data, this means the decision maker's log-odds of choosing between alternatives changes by approximately 3 for each unit difference in normalized SEU.

2. **Cross-study comparability:** Two studies using the same normalization can meaningfully compare estimated Î± values - they measure sensitivity on the same scale.

3. **Prior specification is interpretable:** When we set `alpha ~ lognormal(0, 1)`, we're placing prior mass on interpretable sensitivity levels relative to the unit scale.

4. **Model predictions are identifiable:** The model makes sharp predictions about choice probabilities given (Ïˆ, Ï…, Î±), and these parameters can be separately estimated from sufficiently rich choice data.

**Without normalization:** We could only identify the product Î±Â·a where a is the unknown utility scale. We couldn't separately interpret "sensitivity" from "utility scale."

**With normalization:** We fix a = 1/(max Ï… - min Ï…), making Î± interpretable as sensitivity per unit of standardized SEU difference.

## 5. Model m_0 Specification

### 5.1 Constructing SEU from Features

In model m_0, we parameterize the components of SEU:

**Subjective probabilities** are determined by alternative features x through:

```
Ïˆâ±¼ = softmax(Î² Â· xâ±¼)
```

where Î² âˆˆ â„^(KÃ—D) maps D-dimensional features to K outcome probabilities.

**Utilities** are ordered with incremental differences:

```
Ï… = cumulative_sum([0, Î´])
```

where Î´ is a (K-1)-simplex ensuring utilities lie in [0,1] and are strictly ordered.

**Subjective expected utility** is then:

```
SEU(j) = Î£â‚– Ïˆâ±¼â‚– Â· Ï…â‚– = Ïˆâ±¼áµ€Ï…
```

**Choice probabilities** follow:

```
P(choose j | Î±, Î², Î´, x) = exp(Î± Â· SEU(j)) / Î£â‚– exp(Î± Â· SEU(k))
```

### 5.2 Theoretical Guarantees

Properties 1-3 ensure that:

1. Posterior inference on Î± has a clear interpretation: higher inferred Î± means choices are more consistent with SEU maximization

2. The model nests both deterministic SEU maximization (Î± â†’ âˆ) and random choice (Î± â†’ 0) as limiting cases

3. Intermediate values of Î± capture bounded rationality where decision makers are sensitive to SEU differences but make probabilistic choices

### 5.3 SEU Maximizer Selection

An important diagnostic for understanding model behavior is tracking whether agents select SEU-maximizing alternatives. For each decision problem m, we can define:

**SEU Maximizer Indicator:**
```
I_m = 1 if chosen alternative j* satisfies Î·(j*) = max_j Î·(j)
     0 otherwise
```

where Î·(j) is the expected utility of alternative j.

**Expected SEU Maximizer Selection:** Under the softmax choice model with sensitivity Î±, the probability of selecting an SEU maximizer for problem m is:

```
P(select SEU max | m, Î±) = Î£_{j âˆˆ A*_m} exp(Î±Â·Î·(j)) / Î£_{k=1}^{N_m} exp(Î±Â·Î·(k))
```

where A*_m is the set of SEU-maximizing alternatives in problem m.

**Theoretical Properties:**

1. **As Î± â†’ âˆ:** P(select SEU max | m, Î±) â†’ 1 for all m
2. **As Î± â†’ 0:** P(select SEU max | m, Î±) â†’ |A*_m|/N_m (probability under random choice)
3. **Monotonicity:** P(select SEU max | m, Î±) is strictly increasing in Î±

**Aggregate Analysis:** The total number of SEU maximizers selected across M problems follows:

```
T = Î£_{m=1}^M I_m
```

Under prior predictive analysis, T provides a summary measure of how often the model generates "rational" choices given the prior distributions on parameters.

## 6. Implications for Rational Choice Theory

### 6.1 Generality of Results

The fact that Properties 1-3 hold for *any* value function V reveals an important insight: these properties characterize the softmax choice rule itself, not the specific theory of value.

This means:
- The monotonicity, limiting behavior, and convergence properties are **structural features** of softmax choice
- They would hold equally for risk-neutral expected value, prospect theory values, or any other value construction
- The choice of SEU as our value function is a **substantive theoretical commitment** about what drives behavior

### 6.2 SEU as a Rational Standard

By choosing V = SEU, we commit to SEU maximization as our rationality criterion. This commitment:

1. Aligns with classical Bayesian decision theory (Savage, 1954)
2. Provides a normative benchmark for evaluating choice behavior
3. Makes our parameter Î± interpretable as "degree of rationality" relative to this specific standard

### 6.3 Alternative Value Functions

Our framework could accommodate other value functions:
- **Expected value:** V(j) = Î£áµ¢ Ïˆâ±¼(Ï‰áµ¢)Â·Ï‰áµ¢ (objective outcomes, no utilities)
- **Prospect theory:** V(j) = Î£áµ¢ w(Ïˆâ±¼(Ï‰áµ¢))Â·v(Ï…â±¼(Ï‰áµ¢)) (probability weighting, reference dependence)
- **Regret theory:** V(j) = f(Ï…â±¼, max_k Ï…â‚–) (comparative evaluation)

Each would satisfy Properties 1-3, but yield different substantive predictions about choice behavior.

## 7. Technical Notes

### 7.1 Uniqueness of Maximum

When |A*| = 1 (unique maximum), Property 2 shows deterministic optimal choice as Î± â†’ âˆ.

When |A*| > 1 (multiple optima), the limiting distribution is uniform over A*, representing rational indifference between equally valued alternatives.

### 7.2 Rate of Convergence

- **Property 2 (Î± â†’ âˆ):** Convergence is exponential with rate Î” = min{V* - V(j) : j âˆ‰ A*}
- **Property 3 (Î± â†’ 0):** Convergence is polynomial (first-order in Î±)

### 7.3 Numerical Implementation

For computational stability:
- Large Î±: Use log-sum-exp trick: log(Î£â±¼ exp(xâ±¼)) = max(x) + log(Î£â±¼ exp(xâ±¼ - max(x)))
- Small Î±: Taylor expansion may provide better accuracy than direct evaluation

### 7.4 Connection to Information Theory

The softmax choice model can be derived as the maximum entropy distribution subject to the constraint ğ”¼[V] = c, revealing deep connections to information theory and statistical mechanics.

## 8. References

**Softmax/Luce choice:**
- Luce, R. D. (1959). *Individual Choice Behavior: A Theoretical Analysis*
- McFadden, D. (1973). Conditional logit analysis of qualitative choice behavior

**Quantal response:**
- McKelvey, R. D., & Palfrey, T. R. (1995). Quantal response equilibria for normal form games

**Subjective expected utility:**
- Savage, L. J. (1954). *The Foundations of Statistics*
- Anscombe, F. J., & Aumann, R. J. (1963). A definition of subjective probability

**Information theory connection:**
- Jaynes, E. T. (1957). Information theory and statistical mechanics
- Cover, T. M., & Thomas, J. A. (2006). *Elements of Information Theory*
