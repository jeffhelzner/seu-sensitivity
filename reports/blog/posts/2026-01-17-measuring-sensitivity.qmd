---
title: "Commitment, Performance, and Sensitivity"
description: |
  People may be committed to expected utility maximization even when their performance falls short. We introduce sensitivity as a measure of how strongly choices respond to that commitment.
date: "2026-01-17"
categories: [foundations, rationality, decision-theory]
draft: true
---

## The Irrationality Verdict

In their famous experiments on decision making under uncertainty and risk, Daniel Kahneman and Amos Tversky purported to show that people systematically violate the norms of expected utility theory. Subjects in their studies exhibited patterns like loss aversion, framing effects, and probability weighting that seem incompatible with expected utility maximization. These findings have been widely cited as evidence that humans are fundamentally irrational agents—that we simply do not maximize expected utility when making decisions.

But should we accept this verdict so readily?

## Performance and Commitment

The philosopher Isaac Levi drew a useful distinction between *performance* and *commitment* in decision making. Performance refers to the actual choices an agent makes in specific situations. Commitment refers to the principles or strategies that an agent endorses for making decisions in general—what they would recognize, upon reflection, as the standard they aim to meet.

Levi argued that even if people sometimes make choices that deviate from the norms of rational choice, they can still be *committed* to those principles. A chess player who blunders under time pressure hasn't abandoned their commitment to playing good chess. A student who makes arithmetic errors on an exam hasn't rejected the laws of mathematics. The failures are failures of performance, not of commitment.

This raises an interesting question: Do experiments like those of Kahneman and Tversky demonstrate that people have abandoned expected utility maximization as a normative standard? Or do they merely reveal systematic failures of performance—failures that occur even as subjects remain committed, in some sense, to making choices that maximize their expected utility?

## Modeling Limited Sensitivity

In this project, we're exploring a model that takes this distinction seriously. We consider a decision maker who is *committed* to subjective expected utility maximization but who has a *limited sensitivity* to the implications of that commitment. Such an agent aims to choose the option with highest expected utility but doesn't always succeed—sometimes falling short due to cognitive limitations, noise, or the difficulty of the decision problem at hand.

The key insight is that "limited sensitivity" can be made precise. We introduce a parameter $\alpha$ that governs how strongly the agent's choices respond to differences in expected utility:

$$
P(\text{choose } j) = \frac{\exp(\alpha \cdot EU_j)}{\sum_k \exp(\alpha \cdot EU_k)}
$$

When $\alpha$ is small, the agent is only weakly sensitive to expected utility—their choices appear nearly random, even though they remain committed to the EU standard. As $\alpha$ grows, choices increasingly favor the EU-maximizing option. In the limit, the agent performs perfectly.

This isn't a new mathematical form—it's the familiar softmax or logit choice model. What we're suggesting is a particular *interpretation*: the parameter $\alpha$ measures not whether the agent is rational, but how successfully their performance tracks their commitment.

## Why This Framing Matters

If this interpretation is on the right track, it provides another way to view the experimental evidence.

Rather than asking "Do people maximize expected utility?" we can ask: "Can observed choice data be modeled as if generated by an EU-committed agent with limited sensitivity? And if so, what is that sensitivity, and what factors affect it?"

This reframing opens several avenues:

- **Individual differences:** Some people may be more sensitive than others. We can estimate $\alpha$ for individuals and study what predicts variation.

- **Contextual effects:** Sensitivity might vary with cognitive load, time pressure, or the stakes involved. The same person might show higher $\alpha$ in some conditions than others.

- **AI systems:** Large language models are increasingly used for decision-relevant tasks. We can ask the same questions: Can an LLM's choices be modeled as EU-committed with limited sensitivity? How does sensitivity vary with prompting strategy?

## Exploratory Status

We want to be clear about the status of this project. We are not claiming to have definitively resolved the debate about human rationality. We are not asserting that the Kahneman-Tversky findings have been misinterpreted. We are exploring an idea—developing the formal machinery to take the performance/commitment distinction seriously in empirical work, and seeing where it leads.

The [technical details](/foundations/01_abstract_formulation.qmd) are available for those who want to examine the framework more closely. In future posts, we'll discuss the challenges of applying this framework to realistic decisions (where consequences are complex) and share early findings from experiments with both human and AI decision makers.

We welcome engagement from philosophers of decision theory, psychologists studying judgment and choice, and AI researchers interested in the rationality of language models. The questions here sit at the intersection of these fields, and we suspect the answers will require insights from all of them.

---

*This is the first post in a series on the [SEU Sensitivity project](/).*
